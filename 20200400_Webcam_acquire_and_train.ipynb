{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20200400 Webcam acquire and train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dPKtDgPb1OHE",
        "q6ZZplrQsD96",
        "4tfBzrr-fl_b"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/actionsolve/article25/blob/master/20200400_Webcam_acquire_and_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo-mTOzI9KjW",
        "colab_type": "text"
      },
      "source": [
        "# Demo Webcam Acquisition and Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5flpveKFB-TK",
        "colab_type": "text"
      },
      "source": [
        "## Instructions to Run\n",
        "1. Ensure this notebook is open in Google colab hosting (ie. check the URL starts with: 'https://colab.research.google.com/...')\n",
        "1. Scroll to the last cell, so the title '**Run**' is visible\n",
        "1. Click on the last cell\n",
        "1. Run the entire notebook, by typing: CTRL + F9\n",
        "  - It may take a minute to run.  \n",
        "  - You should then see somne buttons and a live image from your webcam\n",
        "1. Follow instructions from supporting acticle: \"**How to Train Your Webcam**\"\n",
        "\n",
        "  \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPKtDgPb1OHE",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6yeN42Ti2MZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Force TF version\n",
        "# 2020-04-14: %tensorflow_version 1.x    -> Tensorflow ver: 1.15.2     +  TF.Keras  ver: 2.2.4-tf  + Keras  ver: 2.3.1\n",
        "# 2020-04-14: %tensorflow_version 2.x    -> Tensorflow ver: 2.2.0-rc2  +  TF.Keras  ver: 2.3.0-tf  + Keras  ver: 2.3.1\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kHM43Hb9Dqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import datetime as dt  ; \n",
        "import os\n",
        "import sys              ; print(f'Python        ver: %s.%s.%s   %s' % (*sys.version_info[0:3], sys.platform))\n",
        "import threading\n",
        "import time\n",
        "\n",
        "from cv2 import *       ; print(f'OpenCV        ver: {cv2.__version__}')\n",
        "import numpy as np      ; print(f'Numpy         ver: {np.__version__}')\n",
        "import pandas as pd     ; print(f'Pandas        ver: {pd.__version__}')\n",
        "\n",
        "import ipywidgets as widgets\n",
        "#from ipywidgets import Button, GridBox, Layout, ButtonStyle\n",
        "from google.colab import widgets as colab_widgets  #  For working tabs\n",
        "\n",
        "from IPython.display import Image, HTML, display, display_html, Javascript, Markdown, clear_output\n",
        "#from PIL import Image                            XXX BEWARE also using Image from HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "import PIL\n",
        "import io\n",
        "from base64 import b64encode\n",
        "\n",
        "if False: \n",
        "    import tensorflow as tf          ; print(f'Tensorflow    ver: {tf.__version__}' )  # native: ver: 2.2.0-rc1\n",
        "    import tensorflow.keras as keras ; print(f'Keras         ver: {keras.__version__}' )  #  ver: 2.2.4-tf\n",
        "\n",
        "    #from tensorflow.keras.layers import Input, Dense\n",
        "    from tensorflow.keras.models import model_from_json\n",
        "    # from tensorflow.keras import models, layers\n",
        "\n",
        "    from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    from tensorflow.keras.applications import vgg16\n",
        "    from tensorflow.keras import backend as K\n",
        "\n",
        "    #import tensorflow.python.util.deprecation as deprecation\n",
        "\n",
        "else:\n",
        "    import tensorflow as tf ; print(f'Tensorflow    ver: {tf.__version__}' )  # native: ver: 2.2.0-rc1\n",
        "    import keras            ; print(f'Keras         ver: {keras.__version__}' )  # native ver: 2.2.5\n",
        "\n",
        "    #from keras.layers import Input, Dense\n",
        "    from keras.models import model_from_json\n",
        "\n",
        "    from keras.preprocessing.image import load_img, img_to_array\n",
        "    from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    from keras.applications import vgg16\n",
        "    #from keras.applications import nasnet\n",
        "    from keras import backend as K\n",
        "\n",
        "    #K.tensorflow_backend._SYMBOLIC_SCOPE.value = True\n",
        "\n",
        "    #import tensorflow.python.util.deprecation as deprecation\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53S5sqO7UefU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/bin/ls -al  ~/.keras/models/\n",
        "#!/bin/rm -f  ~/.keras/models/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6ZZplrQsD96",
        "colab_type": "text"
      },
      "source": [
        "## Tools - Image Acquisition and Display\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZhge8F9Sho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Webcam acquisition tools\n",
        "# Heavily plaguarised from https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=buJCl90WhNfq\n",
        "def get_html_live_video(width=640, height=480):\n",
        "    \"\"\"\n",
        "    Get HTML tag for live video display from webcam\n",
        "    \"\"\"\n",
        "    html_video_tag = f'<video id=\"video\" width=\"{width}\" height=\"{height}\" autoplay></video>'\n",
        "    html_video_start_js = \"\"\"\n",
        "    <script>\n",
        "        // Display webcam in video tag.  No audio required\n",
        "        if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n",
        "            navigator.mediaDevices.getUserMedia({ video: true, audio: false }).then(function(stream) {\n",
        "                let video = document.getElementById('video');\n",
        "                video.srcObject = stream;\n",
        "                video.play();\n",
        "            });\n",
        "        }\n",
        "    </script>\n",
        "    \"\"\"\n",
        "    # return HTML(html_video_tag + html_video_js)\n",
        "    return html_video_tag + html_video_start_js\n",
        "\n",
        "def acquire_webcam_image_to_file(filename, image_dims=(640, 480), quality=0.8, verbose=False):\n",
        "    \"\"\"\n",
        "    Acquire image to file\n",
        "    \"\"\"\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "\n",
        "            const div = document.createElement('div');\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Draw video image to canvas, to capture\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "            // Stop video\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data_jpeg_base64 = eval_js(f'takePhoto({quality})')\n",
        "    tokens = data_jpeg_base64.split(',')\n",
        "    if(verbose): print(f'    Acquired {len(tokens[1])} bytes, type: {tokens[0]}')\n",
        "    bytes_jpeg = b64decode(data_jpeg_base64.split(',')[1])\n",
        "    image = PIL.Image.open(io.BytesIO(bytes_jpeg))  # ; print(image.size) \n",
        "\n",
        "    # Resize\n",
        "    (old_width, old_height) = image.size\n",
        "    (new_width, new_height) = image_dims\n",
        "    if( (old_width != new_width) or (old_height != new_height) ):\n",
        "        if(verbose): print(f'    Resizing image {old_width} x {old_height}  ->  {new_width} x {new_height}')\n",
        "        image = image.resize(image_dims, PIL.Image.ANTIALIAS) #; print(image.size)\n",
        "\n",
        "    # Save to file\n",
        "    image.save(filename, optimize=True, quality=75)\n",
        "    if(verbose): print(f'    Saved to {filename}    {image.size[0]} x {image.size[1]}')\n",
        "    return filename, new_width, new_height\n",
        "\n",
        "def stop_live_webcam_video():\n",
        "    js = Javascript('''\n",
        "        function stop_video() {\n",
        "            console.log(\"Stopping HTML video, via JS \" );\n",
        "            const video = document.getElementById('video');\n",
        "            const stream = video.srcObject;\n",
        "            stream.getVideoTracks().forEach(track => track.stop());\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    eval_js(f'stop_video()')\n",
        "    \n",
        "# Test acquire images to file\n",
        "if False:\n",
        "    try:\n",
        "        print('Started')\n",
        "        # Show live video\n",
        "        display(HTML(get_html_live_video(width=100, height=100))) \n",
        "\n",
        "        # Acquire from webcam\n",
        "        filename, img_width, img_height = acquire_webcam_image_to_file('photo.big.jpg', verbose=True)\n",
        "        #print(f'Saved to {filename}    {img_width} x {img_height}')\n",
        "        display(Image(filename))\n",
        "\n",
        "        # Acquire from webcam\n",
        "        filename, img_width, img_height = acquire_webcam_image_to_file('photo.sml.jpg', (224, 224), verbose=True)\n",
        "        #print(f'Saved to {filename}    {img_width} x {img_height}')\n",
        "        display(Image(filename))\n",
        "\n",
        "    except Exception as err:\n",
        "        # Errors will be thrown if the user does not have a webcam or if they do not grant the page permission to access it.\n",
        "        print(str(err))\n",
        "\n",
        "# Test live video show + stop\n",
        "if False:\n",
        "    print('Started')\n",
        "    #display(get_html_live_video()) \n",
        "    display(HTML(get_html_live_video(width=100, height=100))) \n",
        "    print('waiting')\n",
        "    time.sleep(3)\n",
        "    stop_live_webcam_video()\n",
        "    print('stopped')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cev7NBxNS-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simple display of thumbnail images from filename list, in a row, left to right.  Show <10 images for visibility\n",
        "def get_image_as_html_tag(filename, width=200, height=150):\n",
        "    # Load from file and convert to PNG\n",
        "    bytes_png = io.BytesIO()  \n",
        "    image = PIL.Image.open(filename)\n",
        "    image.save(bytes_png, format='png')\n",
        "    image_data = b64encode(bytes_png.getvalue()).decode('utf-8')\n",
        "\n",
        "    # Generate HTML image tag\n",
        "    #html_tag = f\"<img style='width: {width}px; height:{height}px margin: 5px; float: left; border: 1px solid black;' src='data:image/png;base64,{image_data}'/>\"\n",
        "    html_tag = f\"<img style='float: left; ' height='{height}px' width='{width}px' src='data:image/png;base64,{image_data}'/>\"\n",
        "\n",
        "    # print(html_tag) ;  display(HTML(html_tag))\n",
        "    return html_tag\n",
        "\n",
        "def get_results_as_html_tag(model_name, class_name, certainty):\n",
        "\n",
        "    # html_tag = '<table style=\"border: 1px solid black ; overflow: visible; white-space: nowrap;\" width=\"350px\"> '  # <table style=\"width:100%; width:300px\">\n",
        "    html_tag = '<table width=\"350px\"> '  # <table style=\"width:100%; width:300px\">\n",
        "    html_tag += '<col width=\"30%\"><col width=\"50%\"><col width=\"20%\">'\n",
        "    html_tag += '<tr>'\n",
        "    html_tag += '<td><big><big>' ; html_tag += f'<bold>{model_name}</bold>'  ; html_tag += '</big></big></td><td></td><td></td>' \n",
        "    html_tag += '</tr>'\n",
        "    html_tag += '<tr>'\n",
        "    html_tag += '<td></td><td align=\"left\"><big>' ; html_tag += f'<bold>{class_name}</bold>'  ; html_tag += '</big></td>'\n",
        "    html_tag += '<td><big>' ; html_tag += f'{certainty*100:.1f} %'      ; html_tag += '</big></td>'\n",
        "    html_tag += '</tr>'\n",
        "    html_tag += '</table>'\n",
        "    \n",
        "    return html_tag\n",
        "\n",
        "def display_image_thumbnails(filenames, display_id=None, width=200, height=200):\n",
        "    '''\n",
        "    Simple display of thumbnail images from filename list, in a row, left to right.  Keep to < 10 for visibility\n",
        "    '''\n",
        "    image_list_html_tags = ''.join(  [get_image_as_html_tag(filename, width, height) for filename in filenames ] ) #; print(image_list_html_tags)\n",
        "    display_id = display(HTML(image_list_html_tags), display_id=display_id)\n",
        "    return display_id\n",
        "\n",
        "def capture_images_for_class(base_dir, class_name, num_images_to_capture, image_dims, verbose=False):\n",
        "\n",
        "    # Make storage folder for training images\n",
        "    # XXX clear previous\n",
        "    base_dir_for_class = os.path.join(base_dir, class_name)\n",
        "    if not os.path.exists(base_dir_for_class):  \n",
        "        os.makedirs(base_dir_for_class)\n",
        "\n",
        "    # Loop acquiring new images\n",
        "    filenames = []\n",
        "    for image_num in range(num_images_to_capture):\n",
        "\n",
        "        filename = os.path.join(base_dir_for_class, f'image_{image_num:03}.jpg')   \n",
        "        fn, w, h = acquire_webcam_image_to_file(filename, image_dims)\n",
        "        # print(f'    {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}:   Captured: {fn}  {w} x {h}')\n",
        "        log_msg(f'  Captured: {fn}  {w} x {h}')\n",
        "        filenames.append(filename)\n",
        "\n",
        "    return filenames\n",
        "\n",
        "# Test display of results\n",
        "if False:\n",
        "    text_html = get_results_as_html_tag(model_name='Custom CNN', class_name='Bobbits', certainty=0.34)\n",
        "    text_html += get_results_as_html_tag(model_name='Pre-trained CNN', class_name='asdlffkjafjfWidgets', certainty=0.94)\n",
        "    display(HTML(text_html))\n",
        "\n",
        "# Test acquire single set of images + display thumbnails\n",
        "if False:\n",
        "    filenames = []\n",
        "    display_id=None\n",
        "    time_start = dt.datetime.now()  ; print(f'Start: {time_start}')  \n",
        "    for index in range(3):\n",
        "        filename = 'aa' + str(index) + '.jpg'\n",
        "        #acquire_webcam_image_to_file(filename=filename)\n",
        "        acquire_webcam_image_to_file(filename, (224, 224), verbose=False)\n",
        "        # filename, img_width, img_height = acquire_webcam_image_to_file('photo.jpg', (224, 224))\n",
        "        filenames.append(filename)\n",
        "\n",
        "        #clear_output()\n",
        "        #display_id = display_image_thumbnails(filenames, display_id=display_id, width=200, height=150)\n",
        "\n",
        "    time_finish = dt.datetime.now() ; print(f'Fin:   {time_finish},    Elapsed: {(time_finish - time_start).seconds:.2f}')\n",
        "\n",
        "    print(filenames)\n",
        "    #display_image_thumbnails(filenames)\n",
        "    display_image_thumbnails(filenames, width=200, height=150)\n",
        "\n",
        "# Test acquire multiple classes of images, and display\n",
        "if False:\n",
        "    image_width, image_height = 224, 224 \n",
        "    class_names = ( 'AAA',  'BBB')\n",
        "    base_dir = 'test_images'\n",
        "    num_images_to_capture = 3  # Test\n",
        "    image_dims = (image_width, image_height)\n",
        "\n",
        "    filenames = []\n",
        "    for class_name in class_names:\n",
        "\n",
        "        print(f'Class {class_name}')\n",
        "        new_filenames = capture_images_for_class(base_dir, class_name, num_images_to_capture, image_dims) #; print(filenames)\n",
        "        #filenames = ['test_images/AAA/image_000.jpg', 'test_images/AAA/image_001.jpg', 'test_images/AAA/image_002.jpg']\n",
        "        for filename in new_filenames:\n",
        "            filenames.append(filename)\n",
        "        time.sleep(2)\n",
        "\n",
        "    # print(filenames)\n",
        "    display_image_thumbnails(filenames, width=50, height=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tfBzrr-fl_b",
        "colab_type": "text"
      },
      "source": [
        "## Tools - Training and Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqk5W85ohcAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config\n",
        "num_images_to_acquire = 8\n",
        "min_classes_to_train = 2\n",
        "num_training_epochs = 40\n",
        "image_save_path = 'images'\n",
        "image_width, image_height = 224, 224 # 640, 480 # \n",
        "image_dims = (image_width, image_height)\n",
        "\n",
        "# Globals - descope these\n",
        "custom_model = None \n",
        "base_model = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8UjOtqwIjZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tools\n",
        "def rem_dir(base_dir, class_name=None, verbose=False):\n",
        "    import shutil\n",
        "    base_dir_for_class = os.path.join(base_dir, class_name) if class_name else base_dir\n",
        "    if os.path.exists(base_dir_for_class):  \n",
        "        if(verbose): print(f'    Removing {base_dir_for_class}')\n",
        "        shutil.rmtree(base_dir_for_class)\n",
        "    else:\n",
        "        if(verbose): print(f'    Missing dir: {base_dir_for_class}')\n",
        "\n",
        "def diag_print_dir(dir_name, tag_name=''):\n",
        "    dir_list = os.listdir(dir_name) \n",
        "    print(f\"    {tag_name} Dir: {dir_name},  Files: {dir_list}\") \n",
        "\n",
        "def log_msg(msg):\n",
        "    timestamp = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    msg_full = f'{timestamp}: {msg}'\n",
        "\n",
        "    # If output tab available, direct logging there\n",
        "    if 'widget_output' in vars() or 'widget_output' in globals():\n",
        "        with widget_output:\n",
        "            print(msg_full)\n",
        "    else:\n",
        "        print(msg_full)\n",
        "\n",
        "# History plots\n",
        "def plot_training(loss_train, acc_train, loss_valid=None, acc_valid=None):\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "    ax1.plot(loss_train, label='Error', color='red')\n",
        "    if(loss_valid is not None):\n",
        "        ax1.plot(loss_valid, label='Valid')\n",
        "    ax1.set_xlabel('Epochs') ; ax1.set_ylabel('Error')\n",
        "    ax1.set_title('Error')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(acc_train, label='Accuracy', color='blue')\n",
        "    if(acc_valid is not None):\n",
        "        ax2.plot(acc_valid, label='Valid')\n",
        "    ax2.set_xlabel('Epochs') ; ax2.set_ylabel('Accuracy') ; \n",
        "    ax2.set_title('Accuracy')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neAUIqUeq4_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build custom model\n",
        "def get_custom_model(base_model, num_output_classes, verbose=False):\n",
        "\n",
        "    if(verbose): print(f'  Customising model to {num_output_classes} outputs')\n",
        "\n",
        "    # Existing layers should not be trainable\n",
        "    for layer in base_model.layers: layer.trainable = False\n",
        "\n",
        "    # Strip final (most-abstract) layers\n",
        "    # x = base_model.output\n",
        "    x = base_model.layers[-2].output  # Lose final/top layer\n",
        "    #x = base_model.layers[-1].output  # Access final layer\n",
        "\n",
        "    # Add new final layer with softmax activation\n",
        "    layer_preds = keras.layers.Dense(num_output_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create new model\n",
        "    custom_model = keras.models.Model(inputs=base_model.input, outputs=layer_preds)\n",
        "\n",
        "    # Compile model\n",
        "    # https://keras.io/optimizers/\n",
        "    #custom_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False), metrics=['accuracy',])\n",
        "    #custom_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adadelta(), metrics=['accuracy',])\n",
        "    #custom_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(lr=1e-2),  metrics=['accuracy'])\n",
        "    #custom_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999),  metrics=['accuracy'])\n",
        "    custom_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999),  metrics=['accuracy'])\n",
        "  \n",
        "    if(verbose): print(custom_model.summary())\n",
        "    return custom_model\n",
        "\n",
        "# Test model spec\n",
        "if False:\n",
        "    log_msg(f'Started')\n",
        "\n",
        "    def print_model(model, name):\n",
        "        print(f'{name}')\n",
        "        print(f'  Input : {model.input},  shape: {model.input_shape}')\n",
        "        print(f'  Output: {model.output},  shape: {model.output_shape}')\n",
        "\n",
        "    base_model = keras.applications.vgg16.VGG16() # include_top=False)\n",
        "    #base_model = nasnet.NASNetMobile(input_shape=(224, 224, 3), include_top=False)  # include_top=False)    \n",
        "    #base_model = nasnet.NASNetMobile()  # include_top=False) \n",
        "    #base_model = nasnet.NASNetMobile()\n",
        "    print_model(base_model, 'base_model')\n",
        "    #print(base_model.summary())\n",
        "\n",
        "    custom_model = get_custom_model(base_model, num_output_classes=2, verbose=False)\n",
        "    print_model(custom_model, 'custom_model')\n",
        "    #print(custom_model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbKgPq_kwh9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict \n",
        "def get_class_label_from_image(model, filename, show_possibles=False, use_base_class_names=False):\n",
        "\n",
        "    log_msg(f'* get_class_label_from_image({filename})    model={model}')\n",
        "\n",
        "    # Load image from file\n",
        "    image = load_img(filename, target_size=(image_width, image_height))\n",
        "\n",
        "    # convert the image pixels to a numpy array, reshape, and normalise\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    image = vgg16.preprocess_input(image)\n",
        "    #image = nasnet.preprocess_input(image)\n",
        "\n",
        "    # Predict probabilities across all output classes\n",
        "    yhat = model.predict(image)       #; print(yhat) # ->  [[0.00166724 0.9983328 ]]\n",
        "    #if(class_names is not None):\n",
        "    #    assert len(yhat[0]) == len(class_names), f'Inconsistent class list, with trained model ({len(class_names)} != { len(yhat[0]) })'\n",
        "\n",
        "    # Interpret\n",
        "    predictions = yhat[0]  ; log_msg(predictions[:10])\n",
        "\n",
        "    # Get max-likelihood, and label for pediction\n",
        "    max_pred = np.max(predictions)\n",
        "    index_of_max = [i for i in range(len(predictions)) if predictions[i] == max_pred][0]  #; print(index_of_max)\n",
        "\n",
        "    if(use_base_class_names):\n",
        "        # Get most-likely class\n",
        "        #labels = decode_predictions(yhat)  # ; print(labels)  # print('Predicted:', decode_predictions(yhat, top=3)[0])\n",
        "        # eg. yhat -> [[('n04200800', 'shoe_shop', 0.37742418), ('n04070727', 'refrigerator', 0.20702392)...\n",
        "        # [[1.000000e+00 5.988968e-11]]\n",
        "        if 'widget_output' in vars() or 'widget_output' in globals(): \n",
        "            with widget_output:\n",
        "                labels = vgg16.decode_predictions(yhat, top=3)  #; print(labels)  # print('Predicted:', decode_predictions(yhat, top=3)[0])\n",
        "                #labels = nasnet.decode_predictions(yhat, top=3)  #; print(labels)  # print('Predicted:', decode_predictions(yhat, top=3)[0])\n",
        "        else:\n",
        "            labels = vgg16.decode_predictions(yhat, top=3)  #; print(labels)  # print('Predicted:', decode_predictions(yhat, top=3)[0])\n",
        "            #labels = nasnet.decode_predictions(yhat, top=3)  #; print(labels)  # print('Predicted:', decode_predictions(yhat, top=3)[0])\n",
        "        most_likely_class_label = labels[0][0][1]\n",
        "\n",
        "        if show_possibles:\n",
        "            log_msg(f'  Top 3 possibles' )\n",
        "            for label in labels[0]:\n",
        "                log_msg(f'    {label[1]:20}    {label[2]*100:.2f}% ')\n",
        "    else:\n",
        "        # Check model have some class names\n",
        "        assert hasattr(model, 'class_names') and (model.class_names is not None), 'Custom model is missing trained class names'\n",
        "\n",
        "        # Get most-likely class\n",
        "        most_likely_class_label = model.class_names[index_of_max]\n",
        "\n",
        "        if show_possibles:\n",
        "            log_msg(f'  Top {len(predictions)} possibles' )\n",
        "            for index in range(len(predictions)):\n",
        "                log_msg(f'    {model.class_names[index]:20}     ({predictions[index]*100:.2f}%)' )\n",
        "\n",
        "    return most_likely_class_label, max_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkrQoXhPqbV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model from images \n",
        "def train_model(image_path=image_save_path, num_epochs=num_training_epochs, callback_by_epoch=None, verbose=False):\n",
        "\n",
        "    if(verbose): log_msg(f'* train_model({num_epochs} epochs, dims {(image_width, image_height)}, from images path: {image_path})')\n",
        "\n",
        "    # Load images into generator\n",
        "    # https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
        "    if(verbose): log_msg(f'    Loading images from path: \"{image_path}\"   {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} ') ; time_start = time.time()\n",
        "    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, rotation_range=20)\n",
        "    # XXX Hack to direct unwanted logging to 'logging' tab, if available\n",
        "    if 'widget_output' in vars() or 'widget_output' in globals():\n",
        "        with widget_output:\n",
        "            train_generator = datagen.flow_from_directory(image_path, class_mode='categorical',\n",
        "                target_size=(image_width, image_height))\n",
        "    else:\n",
        "        train_generator = datagen.flow_from_directory(image_path, class_mode='categorical',\n",
        "            target_size=(image_width, image_height))\n",
        "    class_names = list(train_generator.class_indices.keys())\n",
        "    if(verbose): log_msg(f'      Class indices map: {train_generator.class_indices}') # .class_indices.keys()\n",
        "    if(verbose): log_msg(f'    Finished  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}   Elapsed: {(time.time() - time_start):.3f}')\n",
        "\n",
        "    # Check enough classes to train\n",
        "    if(len(class_names) > 1):\n",
        "        if(verbose): log_msg(f'    Found classes: {class_names}')\n",
        "    else:\n",
        "        log_msg(f'    ** Not enough classes to train on (only found: {class_names}) **')\n",
        "\n",
        "    # CNN pretrained weights could still be currently downloading from thread, so wait\n",
        "    global model_initialised\n",
        "    while not model_initialised:\n",
        "        if(verbose): log_msg(f'    T: Waiting for weights download ... ')\n",
        "        time.sleep(2)\n",
        "\n",
        "    #K.clear_session()  # Does NOT delete pretrained weights\n",
        "    global base_model, custom_model\n",
        "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "    verbosity = tf.logging.get_verbosity()  # ; deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
        "    base_model = vgg16.VGG16() # include_top=False)\n",
        "    # base_model = nasnet.NASNetMobile() # (input_shape=(224, 224, 3), include_top=False)  # include_top=False)    \n",
        "    tf.logging.set_verbosity(verbosity)  # ; deprecation._PRINT_DEPRECATION_WARNINGS = True\n",
        "\n",
        "    # Custom model\n",
        "    log_msg(f'  T: {base_model}  len(class_names): {len(class_names)}')\n",
        "    custom_model = get_custom_model(base_model, num_output_classes=len(class_names), verbose=False)\n",
        "\n",
        "    # Attach class list, used for training. \n",
        "    custom_model.class_names = class_names\n",
        "\n",
        "    # Callback to show progress\n",
        "    class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_begin(self, epoch, logs=None):\n",
        "            #if(verbose): log_msg(f'    T:   Epoch {epoch:02d},    time: {dt.datetime.now().time()} ')\n",
        "            if callback_by_epoch is not None:\n",
        "                callback_by_epoch(epoch)\n",
        "\n",
        "    # Train\n",
        "    if(verbose): log_msg(f'    Training  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}:  ')\n",
        "    time_start = time.time()    #  or  time_start = dt.datetime.now()\n",
        "    history = custom_model.fit(train_generator, epochs=num_epochs, callbacks=[MyCustomCallback()], verbose=0)\n",
        "    #   steps_per_epoch=len(train_generator), validation_data=test_it, validation_steps=len(test_it), \n",
        "    if(verbose): log_msg(f'    Finished  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}   Elapsed: {(time.time() - time_start):.3f}')\n",
        "\n",
        "    # History plots\n",
        "    if(verbose):   # verbose\n",
        "        log_msg(f'    Avail history fields: {history.history.keys()}' )\n",
        "        plot_training(history.history['loss'], history.history['accuracy']) \n",
        "        #, history.history['val_loss'],  history.history['val_acc'] )\n",
        "\n",
        "# Test ImageDataGenerator\n",
        "if False:\n",
        "    from matplotlib import pyplot\n",
        "\n",
        "    image_width, image_height = 224, 224 # 640, 480 #  \n",
        "    image_dims = (image_width, image_height)\n",
        "    image_path = 'images_test'\n",
        "\n",
        "    # Load images into generator\n",
        "    # https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
        "    print(f'    Loading images from path: \"{image_save_path}\"   {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} ') ; time_start = time.time()\n",
        "    # datagen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1)\n",
        "    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1)\n",
        "    train_generator = datagen.flow_from_directory(image_path, class_mode='categorical', target_size=(image_width, image_height))\n",
        "    class_names = list(train_generator.class_indices.keys())\n",
        "    print(f'      Class indices map: {train_generator.class_indices}') # .class_indices.keys()\n",
        "    print(f'    Finished  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}   Elapsed: {(time.time() - time_start):.3f}')\n",
        "    # generate samples and plot\n",
        "    for i in range(9): # Iterate through batches from generator\n",
        "        # Define subplot\n",
        "        pyplot.subplot(3, 3, i+1)\n",
        "        # Get next batch of images\n",
        "        batch = train_generator.next() # batch is tuple of values, class_names\n",
        "        # convert to unsigned integers for viewing\n",
        "        image = batch[0].astype('uint8')  # batch[0]\n",
        "        # plot raw pixel data\n",
        "        # print(image[0])\n",
        "        pyplot.imshow(image[0])\n",
        "        print(batch[1][0])\n",
        "    # show the figure\n",
        "    pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7TVRe7ahFNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initiate background download of weights in thread\n",
        "def init_load_weights_background(run_in_background=True, verbose=False):\n",
        "    if(verbose): log_msg(f'* initialise_trainable_model()')\n",
        "\n",
        "    def load_weights_background(arg0, arg1):\n",
        "\n",
        "        global base_model\n",
        "        # Allow TF to dump warnings and initialise itself.\n",
        "        if(verbose): log_msg(f'    B: Loading base model   {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}  ')   ; time_start = time.time()\n",
        "        tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "        verbosity = tf.logging.get_verbosity()  # ; deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
        "        K.clear_session()  # Does NOT delete pretrained weights\n",
        "        base_model = vgg16.VGG16() # include_top=False)   # Entire:500MB,  include_top=False : 5MB\n",
        "        #base_model = nasnet.NASNetMobile() # (input_shape=(224, 224, 3), include_top=False)\n",
        "        tf.logging.set_verbosity(verbosity)  # ; deprecation._PRINT_DEPRECATION_WARNINGS = True\n",
        "        if(verbose): log_msg(f'    B: Finished loading base model  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}   Elapsed: {(time.time() - time_start):.3f} ')  \n",
        "        #K.clear_session()  # Does NOT delete pretrained weights\n",
        "\n",
        "        global model_initialised ; model_initialised = True\n",
        "\n",
        "    # Start background download\n",
        "    args_list=(2, 3)  # Arbitrary args to demo passing to thread\n",
        "    if run_in_background:\n",
        "        threading.Thread(target=load_weights_background, args=args_list).start()\n",
        "    else:\n",
        "        load_weights_background(*args_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpJnTnoGGd1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test init, train, predict\n",
        "if False:\n",
        "    print(f'Starting')\n",
        "    # !/bin/rm -f  ~/.keras/models/*\n",
        "\n",
        "    # Init models\n",
        "    global base_model, custom_model\n",
        "    global model_initialised  ; model_initialised = False\n",
        "    init_load_weights_background(verbose=True)\n",
        "\n",
        "    # https://github.com/actionsolve/article25/raw/master/test_images/chic/image_002.jpg\n",
        "    # Explore:       https://github.com/Horea94/Fruit-Images-Dataset/tree/master/Training/Apple%20Braeburn\n",
        "    # Download: wget https://raw.githubusercontent.com/Horea94/Fruit-Images-Dataset/master/Test/Apple%20Braeburn/321_100.jpg\n",
        "\n",
        "    # Setup\n",
        "    class_names = ( 'glass', 'hand')   #  ( 'chic', 'rom')- only 4 images each\n",
        "    image_path_test = 'images_test'\n",
        "    image_file_test0 = os.path.join(image_path_test, class_names[0] + '/image_000.jpg')\n",
        "    image_file_test1 = os.path.join(image_path_test, class_names[1] + '/image_000.jpg')\n",
        "\n",
        "    # Download images if required\n",
        "    if not os.path.exists(image_file_test0):\n",
        "        # Clean out previous\n",
        "        rem_dir(image_path_test, verbose=False) \n",
        "        def download_source_file(class_name, file_names, path_src):\n",
        "            target_path = os.path.join(image_path_test, class_name) \n",
        "            os.makedirs(os.path.join(target_path), exist_ok=True)\n",
        "            for file_name in file_names:\n",
        "                full_url = os.path.join(path_src, file_name)\n",
        "                # !/bin/echo /usr/bin/wget $full_url\n",
        "                !/usr/bin/wget $full_url\n",
        "                !/bin/mv $file_name $target_path\n",
        "\n",
        "        image_list =[f'image_{i:03d}.jpg' for i in range(8)]\n",
        "        download_source_file(class_names[0], image_list, \n",
        "                            f'https://raw.githubusercontent.com/actionsolve/article25/master/test_images_224x224/{class_names[0]}/')\n",
        "        download_source_file(class_names[1], image_list, \n",
        "                            f'https://raw.githubusercontent.com/actionsolve/article25/master/test_images_224x224/{class_names[1]}/')\n",
        "\n",
        "    while not model_initialised:\n",
        "        print(f'    I: Waiting for weights download (to set model_initialised) ... ')\n",
        "        time.sleep(2)\n",
        "\n",
        "    # Train models\n",
        "    print(f'Training model')\n",
        "    #def callback_by_epoch(epoch_num):    print(f'    I: Callback -> Epoch: {epoch_num} ')    \n",
        "    #train_model(image_path=image_path_test, num_epochs=40, callback_by_epoch=callback_by_epoch, verbose=True)\n",
        "    train_model(image_path=image_path_test, num_epochs=20, verbose=True) ; print(f'  model.class_names: {custom_model.class_names}')\n",
        "\n",
        "    # Predict, using trained/custom model\n",
        "    most_likely_class_label, max_pred = get_class_label_from_image(custom_model, image_file_test0, show_possibles=True)\n",
        "    print(f'{most_likely_class_label} ({max_pred*100:.3f}%)' )\n",
        "\n",
        "    # Predict, using base model\n",
        "    #most_likely_class_label, max_pred = get_class_label_from_image(base_model, image_file_test0, show_possibles=True, use_base_class_names=True)\n",
        "    #print(f'{most_likely_class_label} ({max_pred*100:.3f}%)' )\n",
        "\n",
        "    # Predict, using trained/custom model\n",
        "    most_likely_class_label, max_pred = get_class_label_from_image(custom_model, image_file_test1, show_possibles=True)\n",
        "    print(f'{most_likely_class_label} ({max_pred*100:.3f}%)' )\n",
        "    \n",
        "    # Predict, using base model\n",
        "    #most_likely_class_label, max_pred = get_class_label_from_image(base_model, image_file_test1, show_possibles=True, use_base_class_names=True)\n",
        "    #print(f'{most_likely_class_label} ({max_pred*100:.3f}%)' )\n",
        "\n",
        "    print(f'Finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cosfej3WhNvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tools\n",
        "def get_valid_class_list(base_dir, min_num_images=3, verbose=False):\n",
        "\n",
        "    expected_extention = '.jpg'\n",
        "    class_names = []\n",
        "    dir_list = os.listdir(base_dir)   # ; print(dir_list)\n",
        "    for dir_name in dir_list:\n",
        "\n",
        "        # Only want subdirectories\n",
        "        abs_dir_path = os.path.join(base_dir, dir_name) \n",
        "        if(verbose): log_msg(f'  abs_dir_path: [{abs_dir_path}]')    \n",
        "        # print(f'  os.path.isdir(abs_dir_path): {os.path.isdir(abs_dir_path)}')\n",
        "        if( os.access(abs_dir_path, os.R_OK) and os.path.isdir(abs_dir_path) ):\n",
        "\n",
        "            # Check enough images/files present\n",
        "            # file_stat = os.stat(abs_dir_path)  ; print(f'  file_stat  : {file_stat} ')\n",
        "            file_list = [file_name for file_name in os.listdir(abs_dir_path) if file_name.endswith(expected_extention)]\n",
        "            if(verbose): log_msg(f'    Found: {file_list}')\n",
        "            if(len(file_list) >= min_num_images):\n",
        "                class_names.append(dir_name)\n",
        "\n",
        "    # print(f'  {class_names}')\n",
        "    return class_names\n",
        "\n",
        "# Test get avalable class lis from images in directories\n",
        "if False:\n",
        "    # XXX Need 3 dirs, at-least 2 with > images present\n",
        "    base_dir = 'images'\n",
        "    class_names = get_valid_class_list(base_dir, min_num_images=3, verbose=True)\n",
        "    print(f'  classes: {class_names}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijQgYcvxhtFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Handlers\n",
        "layout_buttons = widgets.Layout(width='150px', height='30px')\n",
        "def handler_add_widgets_for_new_class(v_box_classes, row_num, num_images_to_acquire):\n",
        "\n",
        "    log_msg(f'Adding new object to train')\n",
        "\n",
        "    global model_initialised, model_trainable, model_trained\n",
        "    if not model_initialised:\n",
        "        log_msg(f'Initialising model ...')\n",
        "        # XXX\n",
        "        model_initialised = True\n",
        "\n",
        "    # Widgets\n",
        "    txt_class_name = widgets.Text(value='', placeholder='Type a name for the new object', description='Object Name:', disabled=False)\n",
        "    btn_acquire = widgets.Button(description='Take photos', button_style='success', disabled=True, icon='camera', layout=layout_buttons)\n",
        "    box_images = widgets.HBox()\n",
        "    btn_remove = widgets.Button(description='Clear', button_style='danger', disabled = True, icon='remove', layout=layout_buttons)\n",
        "\n",
        "    def acquire_images_and_add(class_name, num_images_to_acquire, image_dims, box_images, verbose=False):\n",
        "        if(verbose): log_msg(f'* acquire_images_and_add({num_images_to_acquire} images to {image_save_path}, {class_name})')\n",
        "        img_filenames = capture_images_for_class(image_save_path, class_name, num_images_to_acquire, image_dims) #; print(filenames)\n",
        "        #img_filenames = ['test_images/AAA/image_000.jpg', 'test_images/AAA/image_001.jpg', 'test_images/AAA/image_002.jpg']\n",
        "        for filename in img_filenames:\n",
        "            html_image = get_image_as_html_tag(filename, width=50, height=50)\n",
        "            w = widgets.HTML(value = html_image,  placeholder='placeholder HTML' ) # XXX\n",
        "            box_images.children += (w,)\n",
        "        return img_filenames\n",
        "\n",
        "    # Wiring\n",
        "    def handler_name_change(obj):\n",
        "        # print(f'  Row: {row_num}, Handling name change [{txt_class_name.value}] class')\n",
        "        # txt_class_name.value = txt_class_name.value.strip()    # XXX No spaces\n",
        "        if(len(txt_class_name.value) > 0):\n",
        "            btn_remove.disabled = False\n",
        "            btn_acquire.disabled = False\n",
        "        else:\n",
        "            btn_remove.disabled = True \n",
        "            btn_acquire.disabled = True\n",
        "\n",
        "    def handler_acquire_for_class(obj):\n",
        "        txt_class_name.disabled = True\n",
        "        btn_acquire.disabled = True  ; btn_acquire.button_style='warning'\n",
        "        seconds_delay = 5 ; seconds_sleep = 1\n",
        "        while seconds_delay > 0:\n",
        "            time.sleep(seconds_sleep)\n",
        "            btn_acquire.description = f'Taking photos in {seconds_delay}s'\n",
        "            seconds_delay -= seconds_sleep\n",
        "        btn_acquire.description = 'Taking photos now'\n",
        "        class_name = txt_class_name.value.strip()\n",
        "        # print(f'  Acquiring for {class_name} class,  Row: {row_num}, ')  # ;  print(f'  obj {obj}')\n",
        "        img_filenames = acquire_images_and_add(class_name, num_images_to_acquire, image_dims, box_images, verbose=True)\n",
        "        # Update other widgets\n",
        "        model_trained = False ; btn_identify.disabled = True\n",
        "        if(len(get_valid_class_list(image_save_path)) >= min_classes_to_train): \n",
        "            model_trainable = True  ; btn_train.disabled = False \n",
        "            # print(f'  ** Enabled training ')  # ;  print(f'  obj {obj}')\n",
        "        #display_image_thumbnails(img_filenames)\n",
        "        btn_acquire.description = 'Take photos' ; btn_acquire.button_style='success'\n",
        "\n",
        "    def handler_clear_class(obj):\n",
        "        # Delete image files\n",
        "        class_name = txt_class_name.value.strip()\n",
        "        rem_dir(image_save_path, class_name, verbose=False)\n",
        "        # Clear widget\n",
        "        txt_class_name.value = ''\n",
        "        txt_class_name.disabled = False\n",
        "        box_images.children = []  # Do the discarded children need 'close()' called on each?\n",
        "        # Update other widgets\n",
        "        model_trained = False ; btn_identify.disabled = True\n",
        "        if(len(get_valid_class_list(image_save_path)) < min_classes_to_train): \n",
        "            model_trainable = False ; btn_train.disabled = True\n",
        "            model_trained = False ; btn_identify.disabled = True\n",
        "\n",
        "    # Wiring\n",
        "    txt_class_name.observe(handler_name_change, names='value')\n",
        "    btn_acquire.on_click(handler_acquire_for_class)\n",
        "    btn_remove.on_click(handler_clear_class)\n",
        "\n",
        "    # Layout for row\n",
        "    h_box = widgets.HBox((txt_class_name, btn_acquire, box_images, btn_remove))\n",
        "    v_box_classes.children += (h_box,)    #; print(f'  Rows: {len(v_box_objects.children)}')\n",
        "\n",
        "def handler_learn_classes(v_box_classes, callback_by_epoch):\n",
        "    log_msg(f'Getting classes from {len(v_box_classes.children)} rows')\n",
        "\n",
        "    # Train\n",
        "    train_model(callback_by_epoch=callback_by_epoch, verbose=True)\n",
        "    model_trained = True; btn_identify.disabled = False\n",
        "\n",
        "def handler_identify(v_box_classes, widget_snapshot, widget_results, show_base_model_results):\n",
        "    # Acquire image and identify\n",
        "    log_msg(f'Identifying')\n",
        "\n",
        "    # Acquire image\n",
        "    image_dims = (image_width, image_height)\n",
        "    filename = 'photo.jpg'\n",
        "    filename, _, _ = acquire_webcam_image_to_file(filename, image_dims)  \n",
        "    widget_snapshot.value = '<h2>Snapshot</h2>' + get_image_as_html_tag(filename, width=300, height=200)\n",
        "\n",
        "    # Identify\n",
        "    global base_model, custom_model\n",
        "    widget_results.value = '<h2>Classification</h2>'\n",
        "\n",
        "    # Present results for custom model\n",
        "    most_likely_class_label, max_pred = get_class_label_from_image(custom_model, filename, show_possibles=True)\n",
        "    log_msg( f'Custom:  Most likely:   {most_likely_class_label}     (approximately {max_pred*100:.2f}%)')\n",
        "    widget_results.value += get_results_as_html_tag('Custom CNN', most_likely_class_label, max_pred)\n",
        "\n",
        "    # Present results for base model\n",
        "    if(show_base_model_results):\n",
        "        most_likely_class_label, max_pred = get_class_label_from_image(base_model, filename, show_possibles=True, use_base_class_names=True)\n",
        "        log_msg( f'Pre-trained:  Most likely:   {most_likely_class_label}     (approximately {max_pred*100:.2f}%)')\n",
        "        widget_results.value += get_results_as_html_tag('Pre-trained CNN', most_likely_class_label, max_pred)\n",
        "\n",
        "def handler_stop_video(obj):\n",
        "    stop_live_webcam_video()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc7r-tfdiF-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Icons from https://www.w3schools.com/icons/icons_reference.asp  -> Font Awesome 4\n",
        "# CSS to enable icons on button widgets:  https://fontawesome.com/icons?d=gallery\n",
        "css_element = HTML('<link rel=\"stylesheet\" href=\"//stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\"/>')\n",
        "\n",
        "# Widgets\n",
        "btn_add_class = widgets.Button(description='Add new object', button_style='success', disabled=False, icon='plus', layout=layout_buttons)\n",
        "btn_train = widgets.Button(description='Learn objects', button_style='success', disabled=True, icon='eye', layout=layout_buttons)\n",
        "btn_identify = widgets.Button(description='Classify snapshot', button_style='success', disabled=True, icon='search-plus', layout=layout_buttons)\n",
        "btn_stop_video = widgets.Button(description='Stop webcam', button_style='danger', disabled=False, icon='hand-stop-o', layout=layout_buttons) \n",
        "\n",
        "widget_training_status = widgets.Label()\n",
        "widget_video = widgets.HTML('<h2>Live Preview</h2>' + get_html_live_video(width=300, height=200), layout=widgets.Layout(width='auto', grid_area='widget_video'))\n",
        "widget_snapshot = widgets.HTML(value = f\" \", layout=widgets.Layout(width='auto', grid_area='widget_snapshot')) \n",
        "widget_results = widgets.HTML(value = f\" \", layout=widgets.Layout(width='auto', grid_area='widget_results'))\n",
        "\n",
        "# https://ipywidgets.readthedocs.io/en/latest/examples/Output%20Widget.html   and 'widget_output.clear_output()'\n",
        "widget_output = widgets.Output(layout={'height': '500px', 'width': '100%', 'border': '1px solid black', 'overflow':'scroll'})\n",
        "\n",
        "v_box_main = widgets.VBox()    # ; print(v_box.children),  num_widget_rows = len(v_box_main.children)\n",
        "v_box_classes = widgets.VBox() \n",
        "h_box_train = widgets.HBox()\n",
        "\n",
        "def handle_callback_by_epoch(epoch_num):\n",
        "    line_length = 80  # characters\n",
        "    num_chars = 1 + int( ( line_length * epoch_num ) / num_training_epochs )\n",
        "    msg = '.' * num_chars\n",
        "    widget_training_status.value = f'Training epoch {1+epoch_num} of {num_training_epochs}: {msg}' \n",
        "\n",
        "# Wiring     \n",
        "btn_add_class.on_click(lambda obj : handler_add_widgets_for_new_class(v_box_classes, len(v_box_classes.children), num_images_to_acquire))\n",
        "btn_train.on_click(lambda obj : handler_learn_classes(v_box_classes, handle_callback_by_epoch))\n",
        "btn_identify.on_click(lambda obj : handler_identify(v_box_classes, widget_snapshot, widget_results, show_base_model_results=False))\n",
        "btn_stop_video.on_click(handler_stop_video)\n",
        "\n",
        "# Layout\n",
        "h_box_train.children = (btn_train, widget_training_status)\n",
        "v_box_main.children = (btn_add_class, v_box_classes, h_box_train, btn_identify)#, h_box_identify, btn_stop_video)\n",
        "children = [widget_video, widget_snapshot, widget_results]\n",
        "areas = ' \"widget_video widget_snapshot widget_results\" '\n",
        "layout=widgets.Layout(width='1200px',  # width='50%'\n",
        "            grid_template_rows='auto',\n",
        "            grid_template_columns='30% 30% 40%',\n",
        "            grid_template_areas=areas)\n",
        "gridbox = widgets.GridBox(children=children, layout=layout)\n",
        "#display(v_box_main, gridbox, btn_stop_video) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6Pfu8MAi4aZ",
        "colab_type": "text"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-aQV7fq_RNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Widget enablement\n",
        "global model_initialised, model_trainable, model_trained\n",
        "model_initialised = False  ; model_trainable = False ; model_trained = False;\n",
        "\n",
        "# Clear the decks\n",
        "rem_dir(image_save_path)\n",
        "v_box_classes.children = []\n",
        "clear_output()\n",
        "\n",
        "# Display\n",
        "display(css_element, v_box_main, gridbox, btn_stop_video) \n",
        "\n",
        "# Ensure logs visible in tab\n",
        "tab_bar = colab_widgets.TabBar(['Main', 'Logging'])\n",
        "with tab_bar.output_to(0, select=True):\n",
        "    print('Click on \"Logging\" tab to see logs')\n",
        "with tab_bar.output_to(1, select=False):\n",
        "    display(widget_output)\n",
        "\n",
        "# Load pre-trained CNN, in background\n",
        "log_msg(f'Loading pre-trained CNN, in background')\n",
        "init_load_weights_background(verbose=True)\n",
        "\n",
        "log_msg(f'Fin layout')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}