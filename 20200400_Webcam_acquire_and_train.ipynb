{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20200400 Webcam acquire and train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dPKtDgPb1OHE",
        "q6ZZplrQsD96",
        "4tfBzrr-fl_b"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/actionsolve/article25/blob/master/20200400_Webcam_acquire_and_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo-mTOzI9KjW",
        "colab_type": "text"
      },
      "source": [
        "# Demo Webcam Acquisition and Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5flpveKFB-TK",
        "colab_type": "text"
      },
      "source": [
        "## Instructions to Run\n",
        "* The full instructions are in supporting acticle: \"**How to Train Your Webcam**\"\n",
        "\n",
        "  \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPKtDgPb1OHE",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6yeN42Ti2MZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Force TF version\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kHM43Hb9Dqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import datetime as dt  ; \n",
        "import os\n",
        "import sys              ; print(f'Python        ver: %s.%s.%s   %s' % (*sys.version_info[0:3], sys.platform))\n",
        "import threading\n",
        "import time\n",
        "\n",
        "import cv2              ; print(f'OpenCV        ver: {cv2.__version__}')\n",
        "import numpy as np      ; print(f'Numpy         ver: {np.__version__}')\n",
        "import pandas as pd     ; print(f'Pandas        ver: {pd.__version__}')\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from google.colab import widgets as colab_widgets  #  For working tabs\n",
        "\n",
        "from IPython.display import Image, HTML, display, Javascript, Markdown, clear_output\n",
        "#from PIL import Image                        XXX BEWARE also using Image from HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64encode, b64decode\n",
        "import PIL\n",
        "import io\n",
        "\n",
        "# Import TensorFlow  + Keras \n",
        "import tensorflow as tf ; print(f'Tensorflow    ver: {tf.__version__}' )  # native: ver: 2.2.0-rc1\n",
        "import keras            ; print(f'Keras         ver: {keras.__version__}' )  # native ver: 2.2.5\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from keras.applications import vgg16\n",
        "from keras import backend as K\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6ZZplrQsD96",
        "colab_type": "text"
      },
      "source": [
        "## Tools - Image Acquisition and Display\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZhge8F9Sho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Webcam acquisition tools\n",
        "# Heavily plaguarised from https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=buJCl90WhNfq\n",
        "def get_html_live_video(width=640, height=480):\n",
        "    \"\"\"\n",
        "    Get HTML tag for live video display from webcam\n",
        "    \"\"\"\n",
        "    html_video_tag = f'<video id=\"video\" width=\"{width}\" height=\"{height}\" autoplay></video>'\n",
        "    html_video_start_js = \"\"\"\n",
        "    <script>\n",
        "        // Display webcam in video tag.  No audio required\n",
        "        const video = document.getElementById('video');\n",
        "        if(video != null) {\n",
        "            if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n",
        "                navigator.mediaDevices.getUserMedia({ video: true, audio: false }).then(function(stream) {\n",
        "                    video.srcObject = stream;\n",
        "                    video.play();\n",
        "                });\n",
        "            }\n",
        "        }\n",
        "    </script>\n",
        "    \"\"\"\n",
        "    # return HTML(html_video_tag + html_video_js)\n",
        "    return html_video_tag + html_video_start_js\n",
        "\n",
        "def acquire_webcam_image_to_file(filename, image_dims=(640, 480), quality=0.8, verbose=False):\n",
        "    \"\"\"\n",
        "    Acquire image from <video> tag, to file\n",
        "    \"\"\"\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Draw video image to canvas, to capture\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "            // Stop video\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data_jpeg_base64 = eval_js(f'takePhoto({quality})')\n",
        "    tokens = data_jpeg_base64.split(',')\n",
        "    if(verbose): print(f'    Acquired {len(tokens[1])} bytes, type: {tokens[0]}')\n",
        "    bytes_jpeg = b64decode(tokens[1])\n",
        "    image = PIL.Image.open(io.BytesIO(bytes_jpeg))  # ; print(image.size) \n",
        "\n",
        "    # Resize\n",
        "    (old_width, old_height) = image.size\n",
        "    (new_width, new_height) = image_dims\n",
        "    if( (old_width != new_width) or (old_height != new_height) ):\n",
        "        if(verbose): print(f'    Resizing image {old_width} x {old_height}  ->  {new_width} x {new_height}')\n",
        "        image = image.resize(image_dims, PIL.Image.ANTIALIAS) #; print(image.size)\n",
        "\n",
        "    # Save to file\n",
        "    image.save(filename, optimize=True, quality=75)\n",
        "    if(verbose): print(f'    Saved to {filename}    {image.size[0]} x {image.size[1]}')\n",
        "    return filename, new_width, new_height\n",
        "\n",
        "def stop_live_webcam_video():\n",
        "    \"\"\"\n",
        "    Stop live update of <video> tag, if found\n",
        "    \"\"\"\n",
        "    js = Javascript('''\n",
        "        function stop_video() {\n",
        "            console.log(\"Stopping HTML video, via JS \" );\n",
        "\n",
        "            const video = document.getElementById('video');\n",
        "            if(video != null) {\n",
        "                const stream = video.srcObject;\n",
        "                stream.getVideoTracks().forEach(track => track.stop());\n",
        "            }\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    eval_js(f'stop_video()')\n",
        "\n",
        "def start_live_webcam_video():\n",
        "    \"\"\"\n",
        "    Start live update of <video> tag, if found\n",
        "    \"\"\"\n",
        "    js = Javascript('''\n",
        "        function start_video() {\n",
        "            console.log(\"Starting HTML video, via JS \" );\n",
        "\n",
        "            // Display webcam in video tag.  No audio required\n",
        "            const video = document.getElementById('video');\n",
        "            if(video != null) {\n",
        "                if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n",
        "                    navigator.mediaDevices.getUserMedia({ video: true, audio: false }).then(function(stream) {\n",
        "                        if(video != null) {\n",
        "                            video.srcObject = stream;\n",
        "                            video.play();\n",
        "                        }\n",
        "                    });\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    eval_js(f'start_video()')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cev7NBxNS-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simple display of thumbnail images from filename list, in a row, left to right.  Show <10 images for visibility\n",
        "def get_image_as_html_tag(filename, width=200, height=150):\n",
        "    \"\"\"\n",
        "    Load image from file, convert to PNG, and return as <image> tag\n",
        "    \"\"\"\n",
        "    bytes_png = io.BytesIO()  \n",
        "    image = PIL.Image.open(filename)\n",
        "    image.save(bytes_png, format='png')\n",
        "    image_data = b64encode(bytes_png.getvalue()).decode('utf-8')\n",
        "\n",
        "    # Generate HTML image tag\n",
        "    #html_tag = f\"<img style='width: {width}px; height:{height}px margin: 5px; float: left; border: 1px solid black;' src='data:image/png;base64,{image_data}'/>\"\n",
        "    html_tag = f\"<img style='float: left; ' height='{height}px' width='{width}px' src='data:image/png;base64,{image_data}'/>\"\n",
        "\n",
        "    # print(html_tag) ;  display(HTML(html_tag))\n",
        "    return html_tag\n",
        "\n",
        "def get_results_as_html_tag(model_name, class_name, certainty):\n",
        "    \"\"\"\n",
        "    Format results into table tag\n",
        "    \"\"\"\n",
        "    # html_tag = '<table style=\"border: 1px solid black ; overflow: visible; white-space: nowrap;\" width=\"350px\"> '  # <table style=\"width:100%; width:300px\">\n",
        "    html_tag =  '<table width=\"350px\"> '  # <table style=\"width:100%; width:300px\">\n",
        "    html_tag += '<col width=\"30%\"><col width=\"50%\"><col width=\"20%\">'\n",
        "    html_tag += '<tr>'\n",
        "    html_tag += '<td><big><big>' ; html_tag += f'<bold>{model_name}</bold>'  ; html_tag += '</big></big></td><td></td><td></td>' \n",
        "    html_tag += '</tr>'\n",
        "    html_tag += '<tr>'\n",
        "    html_tag += '<td></td><td align=\"left\"><big>' ; html_tag += f'<bold>{class_name}</bold>'  ; html_tag += '</big></td>'\n",
        "    html_tag += '<td><big>' ; html_tag += f'{certainty*100:.1f} %'      ; html_tag += '</big></td>'\n",
        "    html_tag += '</tr>'\n",
        "    html_tag += '</table>'\n",
        "    \n",
        "    return html_tag\n",
        "\n",
        "def display_image_thumbnails(filenames, display_id=None, width=200, height=200):\n",
        "    '''\n",
        "    Simple display of thumbnail images from filename list, in a row, left to right.  Keep to < 10 for visibility\n",
        "    '''\n",
        "    image_list_html_tags = ''.join(  [get_image_as_html_tag(filename, width, height) for filename in filenames ] ) #; print(image_list_html_tags)\n",
        "    display_id = display(HTML(image_list_html_tags), display_id=display_id)\n",
        "    return display_id\n",
        "\n",
        "def acquire_images_for_class(base_dir, class_name, num_images_to_capture, image_dims, verbose=False):\n",
        "    \"\"\"\n",
        "    Convenience method to acquire images for given class name\n",
        "    \"\"\"\n",
        "    # Make storage folder for training images\n",
        "    base_dir_for_class = os.path.join(base_dir, class_name)\n",
        "    if not os.path.exists(base_dir_for_class):  \n",
        "        os.makedirs(base_dir_for_class)\n",
        "\n",
        "    # Loop acquiring new images\n",
        "    filenames = []\n",
        "    for image_num in range(num_images_to_capture):\n",
        "\n",
        "        filename = os.path.join(base_dir_for_class, f'image_{image_num:03}.jpg')   \n",
        "        fn, w, h = acquire_webcam_image_to_file(filename, image_dims)\n",
        "        # print(f'    {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}:   Captured: {fn}  {w} x {h}')\n",
        "        log_msg(f'  Captured: {fn}  {w} x {h}')\n",
        "        filenames.append(filename)\n",
        "\n",
        "    return filenames\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tfBzrr-fl_b",
        "colab_type": "text"
      },
      "source": [
        "## Tools - Training and Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqk5W85ohcAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training configuration\n",
        "config = {}\n",
        "config['num_images_to_acquire'] = 8\n",
        "config['image_save_path'] = 'images'\n",
        "config['min_classes_to_train'] = 2\n",
        "config['num_training_epochs'] = 40\n",
        "config['image_width'] = 224\n",
        "config['image_height'] = 224\n",
        "# print(config)\n",
        "\n",
        "# Globals - these should be descoped\n",
        "custom_model = None \n",
        "base_model = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9WUXmmrLCIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output widget to catch all diagnostics, for optional display on tab later\n",
        "# https://ipywidgets.readthedocs.io/en/latest/examples/Output%20Widget.html   and 'widget_output.clear_output()'\n",
        "widget_output = widgets.Output(layout={'height': '500px', 'width': '100%', 'border': '1px solid black', 'overflow':'scroll'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8UjOtqwIjZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tools\n",
        "def rem_dir(base_dir, class_name=None, verbose=False):\n",
        "    \"\"\"\n",
        "    Recursively remove directory tree\n",
        "    \"\"\"\n",
        "    import shutil\n",
        "    base_dir_for_class = os.path.join(base_dir, class_name) if class_name else base_dir\n",
        "    if os.path.exists(base_dir_for_class):  \n",
        "        if(verbose): print(f'    Removing {base_dir_for_class}')\n",
        "        shutil.rmtree(base_dir_for_class)\n",
        "    else:\n",
        "        if(verbose): print(f'    Missing dir: {base_dir_for_class}')\n",
        "\n",
        "def log_msg(msg):\n",
        "    \"\"\"\n",
        "    Log message to output widget, if exists, else stdout\n",
        "    \"\"\"\n",
        "    timestamp = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    msg_full = f'{timestamp}: {msg}'\n",
        "\n",
        "    # If output tab available, direct logging there\n",
        "    if 'widget_output' in vars() or 'widget_output' in globals():\n",
        "        with widget_output:\n",
        "            print(msg_full)\n",
        "    else:\n",
        "        print(msg_full)\n",
        "\n",
        "# History plots\n",
        "def plot_training(loss_train, acc_train, loss_valid=None, acc_valid=None):\n",
        "    \"\"\"\n",
        "    Plot training accuracy + training loss/error\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "    ax1.plot(loss_train, label='Error', color='red')\n",
        "    if(loss_valid is not None):\n",
        "        ax1.plot(loss_valid, label='Valid')\n",
        "    ax1.set_xlabel('Epochs') ; ax1.set_ylabel('Error')\n",
        "    ax1.set_title('Error')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(acc_train, label='Accuracy', color='blue')\n",
        "    if(acc_valid is not None):\n",
        "        ax2.plot(acc_valid, label='Valid')\n",
        "    ax2.set_xlabel('Epochs') ; ax2.set_ylabel('Accuracy') ; \n",
        "    ax2.set_title('Accuracy')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neAUIqUeq4_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_custom_model(base_model, num_output_classes, verbose=False):\n",
        "    \"\"\"\n",
        "    Create new custom model, by stripping final (most-abstract) layer from base model\n",
        "    \"\"\"\n",
        "    if(verbose): print(f'  Customising model to {num_output_classes} outputs')\n",
        "\n",
        "    # Existing layers should not be trainable\n",
        "    for layer in base_model.layers: layer.trainable = False\n",
        "\n",
        "    # Strip final (most-abstract) layer\n",
        "    x = base_model.layers[-2].output\n",
        "\n",
        "    # Add new final layer with softmax activation\n",
        "    layer_preds = keras.layers.Dense(num_output_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create new model\n",
        "    custom_model = keras.models.Model(inputs=base_model.input, outputs=layer_preds)\n",
        "\n",
        "    # Compile model\n",
        "    optimizer = keras.optimizers.Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
        "    custom_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  \n",
        "    if(verbose): print(custom_model.summary())\n",
        "    return custom_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbKgPq_kwh9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict \n",
        "def get_class_label_from_image(model, filename, show_possibles=False, use_base_class_names=False):\n",
        "    \"\"\"\n",
        "    Predict class of given image\n",
        "    \"\"\"\n",
        "    log_msg(f'* get_class_label_from_image({filename})    model={model}')\n",
        "\n",
        "    # Load image from file\n",
        "    image_dims = (config['image_width'], config['image_height'])\n",
        "    image = load_img(filename, target_size=image_dims)\n",
        "\n",
        "    # convert the image pixels to a numpy array, reshape, and normalise\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    image = vgg16.preprocess_input(image)\n",
        "\n",
        "    # Predict probabilities across all output classes\n",
        "    yhat = model.predict(image)       #; print(yhat) # ->  [[0.00166724 0.9983328 ]]\n",
        "    #if(class_names is not None):\n",
        "    #    assert len(yhat[0]) == len(class_names), f'Inconsistent class list, with trained model ({len(class_names)} != { len(yhat[0]) })'\n",
        "\n",
        "    # Interpret\n",
        "    predictions = yhat[0]  ; log_msg(predictions[:10])\n",
        "\n",
        "    # Get max-likelihood, and label for pediction\n",
        "    max_pred = np.max(predictions)\n",
        "    index_of_max = [i for i in range(len(predictions)) if predictions[i] == max_pred][0]  #; print(index_of_max)\n",
        "\n",
        "    if(use_base_class_names):\n",
        "        # Get most-likely class\n",
        "        with widget_output:\n",
        "            labels = vgg16.decode_predictions(yhat, top=3)  #; print(labels)  # print('Predicted:', decode_predictions(yhat, top=3)[0])\n",
        "        most_likely_class_label = labels[0][0][1]\n",
        "\n",
        "        if show_possibles:\n",
        "            log_msg(f'  Top ranked possibles' )\n",
        "            for label in labels[0]:\n",
        "                log_msg(f'    {label[1]:20}    {label[2]*100:.2f}% ')\n",
        "    else:\n",
        "        # Check model has expected class names\n",
        "        assert hasattr(model, 'class_names') and (model.class_names is not None), 'Custom model is missing trained class names'\n",
        "\n",
        "        # Get most-likely class\n",
        "        most_likely_class_label = model.class_names[index_of_max]\n",
        "\n",
        "        if show_possibles:\n",
        "            log_msg(f'  Top {len(predictions)} ranked possibles' )\n",
        "            for index in range(len(predictions)):\n",
        "                log_msg(f'    {model.class_names[index]:20}     ({predictions[index]*100:.2f}%)' )\n",
        "\n",
        "    return most_likely_class_label, max_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkrQoXhPqbV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(image_path=config['image_save_path'] , num_epochs=config['num_training_epochs'], callback_by_epoch=None, verbose=False):\n",
        "    \"\"\"\n",
        "    Initialise model and train on source images\n",
        "    \"\"\"\n",
        "    image_dims = (config['image_width'], config['image_height'])\n",
        "    if(verbose): log_msg(f'* train_model({num_epochs} epochs, dims {image_dims}, from images path: {image_path})')\n",
        "\n",
        "    # Load images into generator\n",
        "    # https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
        "    if(verbose): log_msg(f'    Loading images from path: \"{image_path}\"   {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} ') ; time_start = time.time()\n",
        "    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, rotation_range=20)\n",
        "    # Direct unwanted logging to output widget\n",
        "    with widget_output:\n",
        "        train_generator = datagen.flow_from_directory(image_path, class_mode='categorical', target_size=image_dims)\n",
        "    class_names = list(train_generator.class_indices.keys())\n",
        "    if(verbose): log_msg(f'      Class indices map: {train_generator.class_indices}') # .class_indices.keys()\n",
        "    if(verbose): log_msg(f'    Finished  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}   Elapsed: {(time.time() - time_start):.3f}')\n",
        "\n",
        "    # Check enough classes to train\n",
        "    if(len(class_names) > 1):\n",
        "        if(verbose): log_msg(f'    Found classes: {class_names}')\n",
        "    else:\n",
        "        log_msg(f'    ** Not enough classes to train on (only found: {class_names}) **')\n",
        "\n",
        "    # Wait until CNN pretrained weights downloaded and usable\n",
        "    global model_initialised\n",
        "    while not model_initialised:\n",
        "        if(verbose): log_msg(f'    T: Waiting for weights download ... ')\n",
        "        time.sleep(2)\n",
        "\n",
        "    #K.clear_session()  # Does NOT delete pretrained weights\n",
        "    global base_model, custom_model\n",
        "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "    verbosity = tf.logging.get_verbosity()  # ; deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
        "    base_model = vgg16.VGG16() # include_top=False)  \n",
        "    tf.logging.set_verbosity(verbosity)  # ; deprecation._PRINT_DEPRECATION_WARNINGS = True\n",
        "\n",
        "    # Custom model\n",
        "    log_msg(f'  T: {base_model}  len(class_names): {len(class_names)}')\n",
        "    custom_model = get_custom_model(base_model, num_output_classes=len(class_names), verbose=False)\n",
        "\n",
        "    # Attach class list, used for training. \n",
        "    custom_model.class_names = class_names\n",
        "\n",
        "    # Callback to show progress\n",
        "    class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_begin(self, epoch, logs=None):\n",
        "            #if(verbose): log_msg(f'    T:   Epoch {epoch:02d},    time: {dt.datetime.now().time()} ')\n",
        "            if callback_by_epoch is not None:\n",
        "                callback_by_epoch(epoch)\n",
        "\n",
        "    # Train\n",
        "    if(verbose): log_msg(f'    Training  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}:  ')\n",
        "    time_start = time.time()    #  or  time_start = dt.datetime.now()\n",
        "    history = custom_model.fit(train_generator, epochs=num_epochs, callbacks=[MyCustomCallback()], verbose=0)\n",
        "    if(verbose): log_msg(f'    Finished  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}   Elapsed: {(time.time() - time_start):.3f}')\n",
        "\n",
        "    # History plots\n",
        "    if(verbose):   # verbose\n",
        "        log_msg(f'    Avail history fields: {history.history.keys()}' )\n",
        "        with widget_output:\n",
        "            plot_training(history.history['loss'], history.history['accuracy']) \n",
        "            #, history.history['val_loss'],  history.history['val_acc'] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7TVRe7ahFNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_load_weights_background(run_in_background=True, verbose=False):\n",
        "    \"\"\"\n",
        "    Initiate background download of weights in thread\n",
        "    \"\"\"\n",
        "    if(verbose): log_msg(f'* initialise_trainable_model()')\n",
        "\n",
        "    def load_weights_background(arg0, arg1):\n",
        "\n",
        "        global base_model\n",
        "        # Allow TF to dump warnings and initialise itself.\n",
        "        if(verbose): log_msg(f'    B: Loading base model   {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}  ')   ; time_start = time.time()\n",
        "        tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "        verbosity = tf.logging.get_verbosity()  # ; deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
        "        K.clear_session()  # Does NOT delete pretrained weights\n",
        "        base_model = vgg16.VGG16() # include_top=False)   # Entire:500MB,  include_top=False : 5MB\n",
        "        tf.logging.set_verbosity(verbosity)  # ; deprecation._PRINT_DEPRECATION_WARNINGS = True\n",
        "        if(verbose): log_msg(f'    B: Finished loading base model  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}   Elapsed: {(time.time() - time_start):.3f} ')  \n",
        "        #K.clear_session()  # Does NOT delete pretrained weights\n",
        "\n",
        "        global model_initialised ; model_initialised = True\n",
        "\n",
        "    # Start background download\n",
        "    args_list=(2, 3)  # Arbitrary args to demo passing to thread\n",
        "    if run_in_background:\n",
        "        threading.Thread(target=load_weights_background, args=args_list).start()\n",
        "    else:\n",
        "        load_weights_background(*args_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cosfej3WhNvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_valid_class_list(base_dir, min_num_images=3, verbose=False):\n",
        "    \"\"\"\n",
        "    Get list of usable classes, based on checking number of images in subfolders (named by class)\n",
        "    \"\"\"\n",
        "    expected_extention = '.jpg'\n",
        "    class_names = []\n",
        "    dir_list = os.listdir(base_dir)   # ; print(dir_list)\n",
        "    for dir_name in dir_list:\n",
        "\n",
        "        # Only want subdirectories\n",
        "        abs_dir_path = os.path.join(base_dir, dir_name) \n",
        "        if(verbose): log_msg(f'  abs_dir_path: [{abs_dir_path}]')    \n",
        "        # print(f'  os.path.isdir(abs_dir_path): {os.path.isdir(abs_dir_path)}')\n",
        "        if( os.access(abs_dir_path, os.R_OK) and os.path.isdir(abs_dir_path) ):\n",
        "\n",
        "            # Check enough images/files present\n",
        "            # file_stat = os.stat(abs_dir_path)  ; print(f'  file_stat  : {file_stat} ')\n",
        "            file_list = [file_name for file_name in os.listdir(abs_dir_path) if file_name.endswith(expected_extention)]\n",
        "            if(verbose): log_msg(f'    Found: {file_list}')\n",
        "            if(len(file_list) >= min_num_images):\n",
        "                class_names.append(dir_name)\n",
        "\n",
        "    # print(f'  {class_names}')\n",
        "    return class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijQgYcvxhtFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Handlers\n",
        "layout_buttons = widgets.Layout(width='150px', height='30px')\n",
        "def handler_add_widgets_for_new_class(v_box_classes, row_num):\n",
        "\n",
        "    log_msg(f'Adding new object to train')\n",
        "\n",
        "    # Widgets\n",
        "    txt_class_name = widgets.Text(value='', placeholder='Type a name for the new object', description='Object Name:', disabled=False)\n",
        "    btn_acquire = widgets.Button(description='Take photos', button_style='success', disabled=True, icon='camera', layout=layout_buttons)\n",
        "    box_images = widgets.HBox()\n",
        "    btn_remove = widgets.Button(description='Clear', button_style='danger', disabled = True, icon='remove', layout=layout_buttons) \n",
        "\n",
        "    def acquire_images_and_add(class_name, box_images, verbose=False):\n",
        "        if(verbose): log_msg(f'* acquire_images_and_add({config[\"num_images_to_acquire\"]} images to {config[\"image_save_path\"] }, {class_name})')\n",
        "        image_dims = (config['image_width'], config['image_height'])\n",
        "        img_filenames = acquire_images_for_class(config['image_save_path'] , class_name, config['num_images_to_acquire'], image_dims) #; print(filenames)\n",
        "        #img_filenames = ['test_images/AAA/image_000.jpg', 'test_images/AAA/image_001.jpg', 'test_images/AAA/image_002.jpg']\n",
        "        for filename in img_filenames:\n",
        "            html_image = get_image_as_html_tag(filename, width=50, height=50)\n",
        "            w = widgets.HTML(value = html_image,  placeholder='placeholder HTML' ) # XXX\n",
        "            box_images.children += (w,)\n",
        "        return img_filenames\n",
        "\n",
        "    # Wiring\n",
        "    def handler_name_change(obj):\n",
        "        # print(f'  Row: {row_num}, Handling name change [{txt_class_name.value}] class')\n",
        "        txt_class_name.value = txt_class_name.value.strip()    # XXX No spaces\n",
        "        if(len(txt_class_name.value) > 0):\n",
        "            btn_remove.disabled = False\n",
        "            btn_acquire.disabled = False\n",
        "        else:\n",
        "            btn_remove.disabled = True \n",
        "            btn_acquire.disabled = True\n",
        "\n",
        "    def handler_acquire_for_class(obj):\n",
        "        txt_class_name.disabled = True\n",
        "        btn_acquire.disabled = True  ; btn_acquire.button_style='warning'\n",
        "        seconds_delay = 5 ; seconds_sleep = 1\n",
        "        while seconds_delay > 0:  # Simple, innaccurate delay\n",
        "            time.sleep(seconds_sleep)\n",
        "            btn_acquire.description = f'Taking photos in {seconds_delay}s'\n",
        "            seconds_delay -= seconds_sleep\n",
        "        btn_acquire.description = 'Taking photos now'\n",
        "        class_name = txt_class_name.value.strip()\n",
        "        # print(f'  Acquiring for {class_name} class,  Row: {row_num}, ')  # ;  print(f'  obj {obj}')\n",
        "        img_filenames = acquire_images_and_add(class_name, box_images, verbose=True)\n",
        "        # Update other widgets\n",
        "        btn_identify.disabled = True\n",
        "        if(len(get_valid_class_list(config['image_save_path'])) >= config['min_classes_to_train'] ): \n",
        "            btn_train.disabled = False \n",
        "            # print(f'  ** Enabled training ')  # ;  print(f'  obj {obj}')\n",
        "        #display_image_thumbnails(img_filenames)\n",
        "        btn_acquire.description = 'Take photos' ; btn_acquire.button_style='success'\n",
        "\n",
        "    def handler_clear_class(obj):\n",
        "        # Delete image files\n",
        "        class_name = txt_class_name.value.strip()\n",
        "        rem_dir(config['image_save_path'], class_name, verbose=False)\n",
        "        # Clear widget\n",
        "        txt_class_name.value = ''\n",
        "        txt_class_name.disabled = False\n",
        "        box_images.children = []  # Do the discarded children need 'close()' called on each?\n",
        "        # Update other widgets\n",
        "        btn_identify.disabled = True\n",
        "        if(len(get_valid_class_list(config['image_save_path'])) < config['min_classes_to_train']): \n",
        "            btn_train.disabled = True ; label_training_status.value = ''\n",
        "            btn_identify.disabled = True\n",
        "\n",
        "    # Wiring\n",
        "    txt_class_name.observe(handler_name_change, names='value')\n",
        "    btn_acquire.on_click(handler_acquire_for_class)\n",
        "    btn_remove.on_click(handler_clear_class)\n",
        "\n",
        "    # Layout for row\n",
        "    h_box = widgets.HBox((txt_class_name, btn_acquire, box_images, btn_remove))\n",
        "    v_box_classes.children += (h_box,)    #; print(f'  Rows: {len(v_box_objects.children)}')\n",
        "\n",
        "def handler_train_model(v_box_classes, callback_by_epoch):\n",
        "    log_msg(f'Getting classes from {len(v_box_classes.children)} rows')\n",
        "\n",
        "    # Train\n",
        "    train_model(callback_by_epoch=callback_by_epoch, verbose=True)\n",
        "    btn_identify.disabled = False\n",
        "\n",
        "def handler_identify(v_box_classes, widget_snapshot, widget_results, show_base_model_results):\n",
        "    # Acquire image and identify\n",
        "    log_msg(f'Identifying')\n",
        "\n",
        "    # Acquire image\n",
        "    image_dims = (config['image_width'], config['image_height'])\n",
        "    filename = 'photo.jpg'\n",
        "    filename, _, _ = acquire_webcam_image_to_file(filename, image_dims)  \n",
        "    widget_snapshot.value = '<h2>Captured Snapshot</h2>' + get_image_as_html_tag(filename, width=300, height=200)\n",
        "\n",
        "    # Identify\n",
        "    global base_model, custom_model\n",
        "    widget_results.value = '<h2>Identification</h2>'\n",
        "\n",
        "    # Present results for custom model\n",
        "    most_likely_class_label, max_pred = get_class_label_from_image(custom_model, filename, show_possibles=True)\n",
        "    log_msg( f'Custom:  Most likely:   {most_likely_class_label}     (approximately {max_pred*100:.2f}%)')\n",
        "    widget_results.value += get_results_as_html_tag('Most-likely', most_likely_class_label, max_pred)\n",
        "\n",
        "    # Present results for base model\n",
        "    if(show_base_model_results):\n",
        "        most_likely_class_label, max_pred = get_class_label_from_image(base_model, filename, show_possibles=True, use_base_class_names=True)\n",
        "        log_msg( f'Pre-trained:  Most likely:   {most_likely_class_label}     (approximately {max_pred*100:.2f}%)')\n",
        "        widget_results.value += get_results_as_html_tag('Pre-trained CNN', most_likely_class_label, max_pred)\n",
        "\n",
        "# def handler_stop_video(obj):\n",
        "def handler_stop_video(btn_enable_live_video):\n",
        "\n",
        "    # Should really toggle on whether video actually enabled on HTML DOM level\n",
        "    btn_enable_live_video.disabled = True\n",
        "    btn_enable_live_video.description = ''\n",
        "    if(btn_enable_live_video.button_style == 'danger'):\n",
        "        stop_live_webcam_video()\n",
        "        btn_enable_live_video.button_style='success'\n",
        "        btn_enable_live_video.description = 'Restart webcam'\n",
        "    else:\n",
        "        start_live_webcam_video()\n",
        "        btn_enable_live_video.button_style = 'danger'\n",
        "        btn_enable_live_video.description = 'Stop webcam'\n",
        "    btn_enable_live_video.disabled = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc7r-tfdiF-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CSS styling\n",
        "# Icons from https://www.w3schools.com/icons/icons_reference.asp  -> gallery:  https://fontawesome.com/icons?d=gallery\n",
        "#css_elements = HTML('<style>body {background-color: #f0fafa;</style> <link rel=\"stylesheet\" href=\"//stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\"/>')\n",
        "css_elements = HTML('<style>body {background-color: #D8E8F8;</style> <link rel=\"stylesheet\" href=\"//stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\"/>')\n",
        "\n",
        "# Widgets\n",
        "btn_add_class = widgets.Button(description='Add new object', button_style='success', disabled=False, icon='plus', layout=layout_buttons)\n",
        "btn_train = widgets.Button(description='Train', button_style='success', disabled=True, icon='eye', layout=layout_buttons)\n",
        "btn_identify = widgets.Button(description='Identify object', button_style='success', disabled=True, icon='search-plus', layout=layout_buttons)\n",
        "btn_enable_live_video = widgets.Button(description='Stop webcam', button_style='danger', disabled=False, icon='hand-stop-o', layout=layout_buttons) \n",
        "label_get_objects = widgets.HTML('<h1>Get Photos of Objects</h1>')\n",
        "label_train_cnn = widgets.HTML('<h1>Train Neural Network</h1>')\n",
        "label_identify_objects = widgets.HTML('<h1>Identify Objects</h1>')\n",
        "label_training_status = widgets.Label()\n",
        "widget_video = widgets.HTML('<h2>Live Preview</h2>' + get_html_live_video(width=300, height=200), layout=widgets.Layout(width='auto', grid_area='widget_video'))\n",
        "widget_snapshot = widgets.HTML(value = f\" \", layout=widgets.Layout(width='auto', grid_area='widget_snapshot')) \n",
        "widget_results = widgets.HTML(value = f\" \", layout=widgets.Layout(width='auto', grid_area='widget_results'))\n",
        "\n",
        "v_box_main = widgets.VBox()    # ; print(v_box.children),  num_widget_rows = len(v_box_main.children)\n",
        "v_box_classes = widgets.VBox() \n",
        "h_box_train = widgets.HBox()\n",
        "\n",
        "def handle_callback_by_epoch(epoch_num):\n",
        "    line_length = 80  # characters\n",
        "    num_training_epochs = config['num_training_epochs']\n",
        "    num_chars = 1 + int( ( line_length * epoch_num ) / num_training_epochs )\n",
        "    msg = '.' * num_chars\n",
        "    label_training_status.value = f'Training epoch {1+epoch_num} of {num_training_epochs}: {msg}' \n",
        "\n",
        "# Wiring     \n",
        "btn_add_class.on_click(lambda obj : handler_add_widgets_for_new_class(v_box_classes, len(v_box_classes.children)))\n",
        "btn_train.on_click(lambda obj : handler_train_model(v_box_classes, handle_callback_by_epoch))\n",
        "btn_identify.on_click(lambda obj : handler_identify(v_box_classes, widget_snapshot, widget_results, show_base_model_results=False))\n",
        "btn_enable_live_video.on_click(lambda obj : handler_stop_video(btn_enable_live_video))\n",
        "\n",
        "# Live preview, snapshot and results display widgets\n",
        "children = [widget_video, widget_snapshot, widget_results]\n",
        "areas = '\"widget_video widget_snapshot widget_results\"'\n",
        "layout = widgets.Layout(width='1200px',  # width='50%'\n",
        "                        grid_template_rows='auto',\n",
        "                        grid_template_columns='30% 30% 40%',\n",
        "                        grid_template_areas=areas)\n",
        "gridbox = widgets.GridBox(children=children, layout=layout)\n",
        "\n",
        "# Layout\n",
        "h_box_train.children = (btn_train, label_training_status)\n",
        "v_box_main.children = (label_get_objects, btn_add_class, v_box_classes, label_train_cnn, h_box_train, label_identify_objects, btn_identify)\n",
        "widgets_to_display = (css_elements, v_box_main, gridbox, btn_enable_live_video, HTML('<br/>')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6Pfu8MAi4aZ",
        "colab_type": "text"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-aQV7fq_RNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear the decks and display widgets\n",
        "rem_dir(config['image_save_path'] )\n",
        "v_box_classes.children = []\n",
        "clear_output() \n",
        "display(*widgets_to_display) \n",
        "\n",
        "# Ensure logging + plots diverted to tab\n",
        "tab_bar = colab_widgets.TabBar(['Main', 'Logging'])\n",
        "with tab_bar.output_to(0, select=True):\n",
        "    print('Click on \"Logging\" tab to see logs')\n",
        "with tab_bar.output_to(1, select=False):\n",
        "    display(widget_output)\n",
        "\n",
        "# Load pre-trained CNN, in background\n",
        "log_msg(f'Loading pre-trained CNN, in background')\n",
        "global model_initialised ; model_initialised = False\n",
        "init_load_weights_background(verbose=True)\n",
        "\n",
        "log_msg(f'Fin layout')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}