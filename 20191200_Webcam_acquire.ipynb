{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20191200 Webcam acquire.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dPKtDgPb1OHE",
        "q6ZZplrQsD96",
        "4tfBzrr-fl_b"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/actionsolve/article25/blob/master/20191200_Webcam_acquire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo-mTOzI9KjW",
        "colab_type": "text"
      },
      "source": [
        "# Demo Webcam acquisition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5flpveKFB-TK",
        "colab_type": "text"
      },
      "source": [
        "## Todo\n",
        "  - Retrain CNN\n",
        "\n",
        "## Done\n",
        "  - capture image sequence\n",
        "  - display thumbnails\n",
        "  - Layouts\n",
        "  \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPKtDgPb1OHE",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6yeN42Ti2MZ",
        "colab_type": "code",
        "outputId": "2f562bc4-30e8-4551-e02f-32efcef6364f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kHM43Hb9Dqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import datetime as dt  ; \n",
        "import os\n",
        "import sys              ; print(f'Python ver    ver: %s.%s.%s   %s' % (*sys.version_info[0:3], sys.platform))\n",
        "import threading\n",
        "import time\n",
        "\n",
        "from cv2 import *       ; print(f'OpenCV        ver: {cv2.__version__}')\n",
        "import numpy as np      ; print(f'Numpy         ver: {np.__version__}')\n",
        "import pandas as pd     ; print(f'Pandas        ver: {pd.__version__}' )\n",
        "\n",
        "import ipywidgets as widgets\n",
        "#from ipywidgets import Button, GridBox, Layout, ButtonStyle\n",
        "from google.colab import widgets as colab_widgets  #  For working tabs\n",
        "\n",
        "from IPython.display import Image, HTML, display, display_html, Javascript, Markdown, clear_output\n",
        "#from PIL import Image                            XXX BEWARE also using Image from HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "import PIL\n",
        "import io\n",
        "from base64 import b64encode\n",
        "\n",
        "if False:\n",
        "    import tensorflow as tf ; print(f'Tensorflow    ver: {tf.__version__}' )  # native: ver: 2.2.0-rc1\n",
        "    import tensorflow.keras as keras           ; print(f'Keras         ver: {keras.__version__}' )  #  ver: 2.2.4-tf\n",
        "\n",
        "    #from tensorflow.keras.layers import Input, Dense\n",
        "    from tensorflow.keras.models import model_from_json\n",
        "    # from tensorflow.keras import models, layers\n",
        "\n",
        "    from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "    from tensorflow.keras.applications.vgg16 import decode_predictions\n",
        "    from tensorflow.keras.applications.vgg16 import VGG16\n",
        "    from tensorflow.keras import backend as K\n",
        "\n",
        "    #import tensorflow.python.util.deprecation as deprecation\n",
        "\n",
        "else:\n",
        "    import tensorflow as tf ; print(f'Tensorflow    ver: {tf.__version__}' )  # native: ver: 2.2.0-rc1\n",
        "    import keras           ; print(f'Keras         ver: {keras.__version__}' )  # native ver: 2.2.5\n",
        "\n",
        "    #from keras.layers import Input, Dense\n",
        "    from keras.models import model_from_json\n",
        "\n",
        "    from keras.preprocessing.image import load_img, img_to_array\n",
        "    from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    from keras.applications.vgg16 import preprocess_input\n",
        "    from keras.applications.vgg16 import decode_predictions\n",
        "    from keras.applications.vgg16 import VGG16\n",
        "    from keras import backend as K\n",
        "\n",
        "    #import tensorflow.python.util.deprecation as deprecation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6ZZplrQsD96",
        "colab_type": "text"
      },
      "source": [
        "## Tools - Image Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZhge8F9Sho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Webcam acquisition tools\n",
        "# Plaguarised from https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=buJCl90WhNfq\n",
        "def get_html_live_video(width=640, height=480):\n",
        "    \"\"\"\n",
        "    Get HTML tag for live video display from webcam\n",
        "    \"\"\"\n",
        "    html_video_tag = f'<video id=\"video\" width=\"{width}\" height=\"{height}\" autoplay></video>'\n",
        "    html_video_start_js = \"\"\"\n",
        "    <script>\n",
        "        // Display webcam in video tag.  No audio required\n",
        "        if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n",
        "            navigator.mediaDevices.getUserMedia({ video: true, audio: false }).then(function(stream) {\n",
        "                let video = document.getElementById('video');\n",
        "                video.srcObject = stream;\n",
        "                video.play();\n",
        "            });\n",
        "        }\n",
        "    </script>\n",
        "    \"\"\"\n",
        "    # return HTML(html_video_tag + html_video_js)\n",
        "    return html_video_tag + html_video_start_js\n",
        "\n",
        "def acquire_webcam_image_to_file(filename, image_dims=(640, 480), await_button_click=True, quality=0.8, verbose=False):\n",
        "    \"\"\"\n",
        "    Acquire image to file\n",
        "    \"\"\"\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(await_button_click, quality) {\n",
        "\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            if(await_button_click) {               \n",
        "                capture.textContent = 'Capture Image';\n",
        "                div.appendChild(capture);\n",
        "            }\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Add button after image canvas\n",
        "            if(await_button_click) {\n",
        "                div.appendChild(capture);\n",
        "            }\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Wait for Capture to be clicked.\n",
        "            if(await_button_click) {\n",
        "                await new Promise((resolve) => capture.onclick = resolve);\n",
        "            }\n",
        "\n",
        "            // Draw video image to canvas, to capture\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "            // Stop video\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data_jpeg_base64 = eval_js(f'takePhoto({str(await_button_click).lower()}, {quality})')\n",
        "    tokens = data_jpeg_base64.split(',')\n",
        "    if(verbose): print(f'    Acquired {len(tokens[1])} bytes, type: {tokens[0]}')\n",
        "    bytes_jpeg = b64decode(data_jpeg_base64.split(',')[1])\n",
        "    image = PIL.Image.open(io.BytesIO(bytes_jpeg))  # ; print(image.size) \n",
        "    old_width, old_height = image.size\n",
        "\n",
        "    # Resize\n",
        "    (new_width, new_height) = image_dims\n",
        "    if( (old_width != new_width) or (old_height != new_height) ):\n",
        "        if(verbose): print(f'    Resizing image {old_width} x {old_height}  ->  {new_width} x {new_height}')\n",
        "        image = image.resize(image_dims, PIL.Image.ANTIALIAS) #; print(image.size)\n",
        "\n",
        "    # Save to file\n",
        "    image.save(filename, optimize=True, quality=95)\n",
        "    if(verbose): print(f'    Saved to {filename}    {image.size[0]} x {image.size[1]}')\n",
        "    # with open(filename, 'wb') as f:        f.write(bytes_jpeg)\n",
        "    return filename, new_width, new_height\n",
        "\n",
        "def stop_live_webcam_video():\n",
        "    js = Javascript('''\n",
        "        function stop_video() {\n",
        "            console.log(\"Stopping HTML video, via JS \" );\n",
        "            const video = document.getElementById('video');\n",
        "            const stream = video.srcObject;\n",
        "            stream.getVideoTracks().forEach(track => track.stop());\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    eval_js(f'stop_video()')\n",
        "    \n",
        "# Test\n",
        "if False:\n",
        "    try:\n",
        "        print('Started')\n",
        "        # Show live video\n",
        "        display(HTML(get_html_live_video(width=100, height=100))) \n",
        "\n",
        "        # Acquire from webcam\n",
        "        filename, img_width, img_height = acquire_webcam_image_to_file('photo.big.jpg', await_button_click=False, verbose=True)\n",
        "        #print(f'Saved to {filename}    {img_width} x {img_height}')\n",
        "        display(Image(filename))\n",
        "\n",
        "        # Acquire from webcam\n",
        "        filename, img_width, img_height = acquire_webcam_image_to_file('photo.sml.jpg', (224, 224), await_button_click=False, verbose=True)\n",
        "        #print(f'Saved to {filename}    {img_width} x {img_height}')\n",
        "        display(Image(filename))\n",
        "\n",
        "    except Exception as err:\n",
        "        # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "        # grant the page permission to access it.\n",
        "        print(str(err))\n",
        "\n",
        "if False:\n",
        "    print('Started')\n",
        "    #display(get_html_live_video()) \n",
        "    display(HTML(get_html_live_video(width=100, height=100))) \n",
        "    print('waiting')\n",
        "    time.sleep(3)\n",
        "    stop_live_webcam_video()\n",
        "    print('stopped')\n",
        "\n",
        "    #clear_output()\n",
        "    #filename, img_width, img_height = acquire_webcam_image_to_file('photo.x.jpg', await_button_click=False, verbose=True)\n",
        "    #print(f'Saved to {filename}    {img_width} x {img_height}')\n",
        "    #display(Image(filename))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cev7NBxNS-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simple display of thumbnail images from filename list, in a row, left to right.  Keep to < 10 for visibility\n",
        "def get_image_as_html_tag(filename, width=200, height=200):\n",
        "    # Convert to PNG bytes\n",
        "    image = PIL.Image.open(filename)\n",
        "    bytes_png = io.BytesIO()  \n",
        "    image.save(bytes_png, format='png')\n",
        "    image_data = b64encode(bytes_png.getvalue()).decode('utf-8')\n",
        "\n",
        "    # Generate HTML image tag\n",
        "    #html_tag = f\"<img style='width: 200px; margin: 5px; float: left; border: 1px solid black;' src='data:image/png;base64,{image_data}'/>\"\n",
        "    html_tag = f\"<img style='width: {width}px; height:{height}px margin: 5px; float: left; border: 1px solid black;' src='data:image/png;base64,{image_data}'/>\"\n",
        "    #display(html_tag) ; display(HTML(html_tag))\n",
        "\n",
        "    return html_tag\n",
        "\n",
        "def get_results_as_html_tag(class_name, certainty):\n",
        "    html_tag = '<table style=\"width:180px; border:1px black\">'  # <table style=\"width:300px\">\n",
        "    html_tag += '<tr>'\n",
        "    html_tag += '<td><big>' ; html_tag += f'<bold>{class_name}</bold>'  ; html_tag += '</big></td>'\n",
        "    html_tag += '<td><big>' ; html_tag += f'{certainty*100:.2f} %'      ; html_tag += '</big></td>'\n",
        "    html_tag += '</tr>'\n",
        "    html_tag += '</table>'\n",
        "    \n",
        "    return html_tag\n",
        "\n",
        "def display_image_thumbnails(filenames, width=200, height=200):\n",
        "    '''\n",
        "    Simple display of thumbnail images from filename list, in a row, left to right.  Keep to < 10 for visibility\n",
        "    '''\n",
        "    image_list_html_tags = ''.join(  [get_image_as_html_tag(filename, width, height) for filename in filenames ] ) #; print(image_list_html_tags)\n",
        "    display(HTML(image_list_html_tags))\n",
        "\n",
        "def capture_images_for_class(base_dir, class_name, num_images_to_capture, image_dims, verbose=False):\n",
        "\n",
        "    # Make storage folder for traiing images\n",
        "    # XXX clear previous\n",
        "    base_dir_for_class = os.path.join(base_dir, class_name)\n",
        "    if not os.path.exists(base_dir_for_class):  \n",
        "        os.makedirs(base_dir_for_class)\n",
        "\n",
        "    # Loop acquiring new images\n",
        "    filenames = []\n",
        "    for image_num in range(num_images_to_capture):\n",
        "\n",
        "        filename = os.path.join(base_dir_for_class, f'image_{image_num:03}.jpg')   \n",
        "        fn, w, h = acquire_webcam_image_to_file(filename, image_dims, await_button_click=False)\n",
        "        # print(f'    {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}:   Captured: {fn}  {w} x {h}')\n",
        "        log_msg(f'  Captured: {fn}  {w} x {h}')\n",
        "        filenames.append(filename)\n",
        "\n",
        "    return filenames\n",
        "\n",
        "# Test\n",
        "if False:\n",
        "    filenames = []\n",
        "    for index in range(3):\n",
        "        filename = 'aa' + str(index) + '.jpg'\n",
        "        #acquire_webcam_image_to_file(filename=filename, await_button_click=False)\n",
        "        acquire_webcam_image_to_file(filename, (224, 224), await_button_click=False, verbose=True)\n",
        "        # filename, img_width, img_height = acquire_webcam_image_to_file('photo.jpg', (224, 224), await_button_click=False)\n",
        "        filenames.append(filename)\n",
        "\n",
        "    print(filenames)\n",
        "    #display_image_thumbnails(filenames)\n",
        "    display_image_thumbnails(filenames, width=50, height=50)\n",
        "\n",
        "if False:\n",
        "    image_width, image_height = 224, 224 \n",
        "    class_names = ( 'AAA',  'BBB')\n",
        "    base_dir = 'test_images'\n",
        "    num_images_to_capture = 3  # Test\n",
        "    image_dims = (image_width, image_height)\n",
        "\n",
        "    filenames = []\n",
        "    for class_name in class_names:\n",
        "\n",
        "        print(f'Class {class_name}')\n",
        "        new_filenames = capture_images_for_class(base_dir, class_name, num_images_to_capture, image_dims) #; print(filenames)\n",
        "        #filenames = ['test_images/AAA/image_000.jpg', 'test_images/AAA/image_001.jpg', 'test_images/AAA/image_002.jpg']\n",
        "        for filename in new_filenames:\n",
        "            filenames.append(filename)\n",
        "        time.sleep(2)\n",
        "\n",
        "    # print(filenames)\n",
        "    display_image_thumbnails(filenames, width=50, height=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tfBzrr-fl_b",
        "colab_type": "text"
      },
      "source": [
        "## Tools - Display and Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqk5W85ohcAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config\n",
        "num_images_to_acquire = 2\n",
        "min_classes_to_train = 2\n",
        "num_training_epochs = 40\n",
        "save_path = 'images'\n",
        "image_width, image_height = 224, 224 \n",
        "image_dims = (image_width, image_height)\n",
        "\n",
        "# Intial weights to use\n",
        "# https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
        "WEIGHTS_FILE_VGG16 = 'vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "#WEIGHTS_FILE_VGG16 = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "WEIGHTS_FILE_SIZE = 553467096  # bytes  notop.h5:58889256    top:553467096  (wget reported corectly too)\n",
        "# os.stat_result(st_mode=33188, st_ino=3941984, st_dev=46, st_nlink=1, st_uid=0, st_gid=0,  st_size=58889256, st_atime=1584428003, st_mtime=1495517769, st_ctime=1584428015) notop: \n",
        "# os.stat_result(st_mode=33188, st_ino=3941984, st_dev=46, st_nlink=1, st_uid=0, st_gid=0, st_size=553467096, st_atime=1584428831, st_mtime=1495517769, st_ctime=1584428841) top\n",
        "WEIGHTS_PATH_VGG16 = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1'\n",
        "WEIGHTS_PATH_LOCAL = '~/.keras/models/'  # Beware '~' not yet expanded to actual directory on local OS\n",
        "\n",
        "# Other initialisations\n",
        "import os\n",
        "WEIGHTS_PATH_LOCAL = os.path.expanduser(WEIGHTS_PATH_LOCAL) ; print(f'  WEIGHTS_PATH_LOCAL: {WEIGHTS_PATH_LOCAL}')\n",
        "WEIGHTS_FILE_LOCAL = os.path.join(WEIGHTS_PATH_LOCAL, WEIGHTS_FILE_VGG16) ; print(f'  WEIGHTS_FILE_LOCAL: {WEIGHTS_FILE_LOCAL}')\n",
        "\n",
        "# Globals - descope these\n",
        "custom_model = None    # XXX Set this \n",
        "base_model = None\n",
        "weights_file_available = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8UjOtqwIjZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def diag_print_dir(dir_name, tag_name=''):\n",
        "    dir_list = os.listdir(dir_name) \n",
        "    print(f\"    {tag_name} Dir: {dir_name},  Files: {dir_list}\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fy7T6Oeapde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Temp debug: remove weights file\n",
        "if True:\n",
        "    # Ensure path exists\n",
        "    os.makedirs(WEIGHTS_PATH_LOCAL, mode=0o777, exist_ok=True)\n",
        "    \n",
        "    diag_print_dir(WEIGHTS_PATH_LOCAL, tag_name='')\n",
        "    #print(f'File: {os.stat(WEIGHTS_FILE_LOCAL).st_size} vs expected: {WEIGHTS_FILE_SIZE}')\n",
        "    !/bin/rm -f  ~/.keras/models/*\n",
        "    diag_print_dir(WEIGHTS_PATH_LOCAL, tag_name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neAUIqUeq4_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build custom model\n",
        "def get_custom_model(base_model, num_output_classes, verbose=False):\n",
        "\n",
        "    if(verbose): print(f'  Customising model to {num_output_classes} outputs')\n",
        "\n",
        "    # These should not be trainable\n",
        "    for layer in base_model.layers: layer.trainable = False\n",
        "\n",
        "    # Strip final (most-abstract) layers\n",
        "    # model.layers.pop()\n",
        "    # x = base_model.output\n",
        "    # x = base_model.layers[-2].output  # Lose final/top layer\n",
        "    x = base_model.layers[-3].output  # Lose final/top 2 layers\n",
        "\n",
        "    # Add new layers\n",
        "    layer_preds = keras.layers.Dense(num_output_classes, activation='softmax')(x) # Final layer with softmax activation\n",
        "\n",
        "    # Create new model\n",
        "    custom_model = keras.models.Model(inputs=base_model.input, outputs=layer_preds)\n",
        "\n",
        "    # Compile model\n",
        "    # XXX Check optimisers\n",
        "    custom_model.compile(loss='categorical_crossentropy', optimizer='AdaDelta', metrics=['accuracy',])\n",
        "    # custom_model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4),  metrics=['acc'])\n",
        "\n",
        "    if(verbose): print(custom_model.summary())\n",
        "    return custom_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2haVxu0tJHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# History plots\n",
        "def plot_training(loss_train, acc_train, loss_valid=None, acc_valid=None):\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "    ax1.plot(loss_train, label='Train', color='red')\n",
        "    if(loss_valid is not None):\n",
        "        ax1.plot(loss_valid, label='Valid')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.set_title('Loss')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(acc_train, label='Train', color='red')\n",
        "    if(acc_valid is not None):\n",
        "        ax2.plot(acc_valid, label='Valid')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.set_title('Accuracy')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def log_msg(msg):\n",
        "    timestamp = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    msg_full = f'{timestamp}: {msg}'\n",
        "    # with tab_bar.output_to(1, select=False):\n",
        "    if 'widget_output' in vars() or 'widget_output' in globals():\n",
        "        with widget_output:\n",
        "            print(msg_full)\n",
        "    else:\n",
        "        print(msg_full)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbKgPq_kwh9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict \n",
        "#def get_class_from_image(filename, class_names, verbose=True):\n",
        "#    global base_model, custom_model\n",
        "#    print(f'* get_class_from_image({filename}, {class_names})    model={custom_model}')\n",
        "#    most_likely_class_label, max_pred = get_class_label_from_image(custom_model, filename, class_names, show_possibles=False)\n",
        "#    # XXX If not good, should alos query base_model\n",
        "#    return most_likely_class_label, max_pred\n",
        "def get_class_label_from_image(model, filename, class_names, show_possibles=False):\n",
        "\n",
        "    log_msg(f'* get_class_label_from_image({filename}, {class_names})    model={model}')\n",
        "\n",
        "    # Load image from file\n",
        "    image = load_img(filename, target_size=(image_width, image_height))\n",
        "\n",
        "    # convert the image pixels to a numpy array, reshape, and normalise\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    image = preprocess_input(image)\n",
        "\n",
        "    # Predict probabilities across all output classes\n",
        "    yhat = model.predict(image)        # ; print(yhat)  ->  [[0.00166724 0.9983328 ]]\n",
        "    assert len(yhat[0]) == len(class_names), 'Inconsistent class list, with trainer model'\n",
        "    predictions = yhat[0]  ; log_msg(predictions)\n",
        "    #labels = decode_predictions(yhat)  # ; print(labels)\n",
        "    # eg. [[('n04200800', 'shoe_shop', 0.37742418), ('n04070727', 'refrigerator', 0.20702392)...\n",
        "    # [[1.000000e+00 5.988968e-11]]\n",
        "\n",
        "    if show_possibles:\n",
        "        log_msg(f'  Top {len(predictions)} possibles' )\n",
        "        for index  in range(len(predictions)):\n",
        "            log_msg(f'    {class_names[index]:20}     ({predictions[index]*100:.2f}%)' )\n",
        "\n",
        "    max_pred = np.max(predictions)\n",
        "    index_of_max = [i for i in range(len(predictions)) if predictions[i] == max_pred][0]  #; print(index_of_max)\n",
        "    most_likely_class_label = class_names[index_of_max]\n",
        "\n",
        "    # Print the classification\n",
        "    #most_likely_class_label = labels[0][0]\n",
        "    #print(f'{most_likely_class_label[1]} ({most_likely_class_label[2]*100:.3f}%)' )\n",
        "\n",
        "    return most_likely_class_label, max_pred\n",
        "    #return 'aaaaa', 0.99"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkrQoXhPqbV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model from images \n",
        "def train_model(verbose=False):\n",
        "\n",
        "    if(verbose): log_msg(f'* train_model(from images path: {save_path})')\n",
        "\n",
        "    # Load images into generator\n",
        "    # https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
        "    if(verbose): log_msg(f'    Loading images from path: \"{save_path}\"   {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} ') ; time_start = time.time()\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "    # XXX Hack to direct unwanted logging to 'logging' tab, if available\n",
        "    if 'widget_output' in vars() or 'widget_output' in globals():\n",
        "        with widget_output:\n",
        "            train_generator = datagen.flow_from_directory(save_path, class_mode='categorical', #class_mode='binary', \n",
        "                target_size=(image_width, image_height))\n",
        "    else:\n",
        "        train_generator = datagen.flow_from_directory(save_path, class_mode='categorical', #class_mode='binary', \n",
        "            target_size=(image_width, image_height))\n",
        "    class_names = list(train_generator.class_indices.keys())\n",
        "    if(verbose): log_msg(f'      Class indices map: {train_generator.class_indices}') # .class_indices.keys()\n",
        "    if(verbose): log_msg(f'    Finished  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}   Elapsed: {(time.time() - time_start):.3f}')\n",
        "\n",
        "    # Check enough classes to train\n",
        "    if(len(class_names) > 1):\n",
        "        if(verbose): log_msg(f'    Found classes: {class_names}')\n",
        "    else:\n",
        "        log_msg(f'    ** Not enough classes to train on (only found: {class_names}) **')\n",
        "\n",
        "    global weights_file_available\n",
        "    while not weights_file_available:\n",
        "        if(verbose): log_msg(f'    T: Waiting for weights download ... ')\n",
        "        time.sleep(2)\n",
        "\n",
        "    #K.clear_session()  # Does NOT delete pretrained weights\n",
        "    global base_model, custom_model\n",
        "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "    verbosity = tf.logging.get_verbosity()\n",
        "    #deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
        "    base_model = VGG16() # include_top=False)   # Entire:500MB,  include_top=False : 5MB\n",
        "    tf.logging.set_verbosity(verbosity)  # tf.logging.INFO)\n",
        "    #deprecation._PRINT_DEPRECATION_WARNINGS = True\n",
        "\n",
        "    # Custom model\n",
        "    log_msg(f'  T: {base_model}  len(class_names): {len(class_names)}')\n",
        "    custom_model = get_custom_model(base_model, num_output_classes=len(class_names), verbose=False)\n",
        "\n",
        "    # Train\n",
        "    if(verbose): log_msg(f'    Training  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}:  ')\n",
        "    time_start = time.time()    #  or  time_start = datetime.now()\n",
        "    history = custom_model.fit(train_generator, \n",
        "        #steps_per_epoch=len(train_generator), validation_data=test_it, validation_steps=len(test_it), \n",
        "        epochs=num_training_epochs, verbose=0)\n",
        "    if(verbose): log_msg(f'    Finished  {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}   Elapsed: {(time.time() - time_start):.3f}')\n",
        "\n",
        "    # History plots\n",
        "    if(verbose):   # verbose\n",
        "        log_msg(f'    Avail history fields: {history.history.keys()}' )\n",
        "        plot_training(history.history['loss'], history.history['acc']) \n",
        "        #, history.history['val_loss'],  history.history['val_acc'] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7TVRe7ahFNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initiate background download of weights in thread\n",
        "def init_load_weights_background(verbose=False):\n",
        "    if(verbose): log_msg(f'* initialise_trainable_model()')\n",
        "    # https://arxiv.org/abs/1409.1556\n",
        "    # https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/\n",
        "\n",
        "    #diag_print_dir(WEIGHTS_PATH_LOCAL, tag_name='')\n",
        "\n",
        "    # Check if weights file already exists, and correct size\n",
        "    global weights_file_available\n",
        "    log_msg(f'  WEIGHTS_FILE_LOCAL: {WEIGHTS_FILE_LOCAL},  expected size: {WEIGHTS_FILE_SIZE}')\n",
        "    #print(f'Checking: {os.stat(WEIGHTS_FILE_LOCAL).st_size} vs {WEIGHTS_FILE_SIZE}')\n",
        "    if(os.access(WEIGHTS_FILE_LOCAL, os.R_OK) and os.stat(WEIGHTS_FILE_LOCAL).st_size == WEIGHTS_FILE_SIZE):\n",
        "        file_stat = os.stat(WEIGHTS_FILE_LOCAL)  # ; print(f'  file_stat  : {file_stat} ')\n",
        "        if(verbose): log_msg(f'    Initial model weights already downloaded : {WEIGHTS_FILE_LOCAL},  {file_stat.st_size} bytes')\n",
        "        weights_file_available = True\n",
        "        return\n",
        "    else:\n",
        "        # Clean slate\n",
        "        if(verbose): log_msg(f'    Clearing models weights directory {WEIGHTS_PATH_LOCAL}')\n",
        "        !/bin/rm -f  $WEIGHTS_PATH_LOCAL/*\n",
        "        # dir_list = os.listdir(WEIGHTS_PATH_LOCAL) ; print(f\"      Dir: {WEIGHTS_PATH_LOCAL},  Files: {dir_list}\")  \n",
        "        weights_file_available = False\n",
        "\n",
        "    # Ensure path exists\n",
        "    os.makedirs(WEIGHTS_PATH_LOCAL, mode=0o777, exist_ok=True)\n",
        "\n",
        "    def load_weights_background(arg0, arg1):\n",
        "\n",
        "        global base_model, custom_model\n",
        "        # Allow TF to dump warnings and initialise itself.\n",
        "        # XXX Warnings and errors will be hidden in thread                   XXX\n",
        "        if(verbose): log_msg(f'    B: Loading VGG16()   {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}  ')   ; time_start = time.time()\n",
        "        tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "        verbosity = tf.logging.get_verbosity()\n",
        "        #deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
        "        K.clear_session()  # Does NOT delete pretrained weights\n",
        "        base_model = VGG16() # include_top=False)   # Entire:500MB,  include_top=False : 5MB\n",
        "        #   VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))\n",
        "        #deprecation._PRINT_DEPRECATION_WARNINGS = True\n",
        "        #tf.logging.set_verbosity(tf.logging.INFO)\n",
        "        tf.logging.set_verbosity(verbosity)  # tf.logging.INFO)\n",
        "        if(verbose): log_msg(f'    B: Finished loading VGG16 {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}   Elapsed: {(time.time() - time_start):.3f} ')  \n",
        "\n",
        "        K.clear_session()  # Does NOT delete pretrained weights\n",
        "        log_msg(f'  B: {base_model}')\n",
        "\n",
        "        global weights_file_available ; weights_file_available = True\n",
        "\n",
        "    # Start background download\n",
        "    args_list=(2, 3)\n",
        "    threading.Thread(target=load_weights_background, args=args_list).start()\n",
        "    #load_weights_background(*args_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpJnTnoGGd1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test init, train, predict\n",
        "if False:\n",
        "    print(f'Starting')\n",
        "\n",
        "    # Init models\n",
        "    global base_model, custom_model\n",
        "    global weights_file_available  ; weights_file_available = False\n",
        "    init_load_weights_background(verbose=True)\n",
        " \n",
        "    download_source_images = False\n",
        "    # Setup\n",
        "    class_names = ('yyy', 'zzz')\n",
        "    if download_source_images:\n",
        "        # Clean out previous\n",
        "        !/bin/rm -rf $save_path\n",
        "        def download_source_file(class_name, file_names, path_src):\n",
        "            target_path = os.path.join(save_path, class_name) \n",
        "            os.makedirs(os.path.join(target_path), exist_ok=True)\n",
        "            for file_name in file_names:\n",
        "                #!wget https://raw.githubusercontent.com/Horea94/Fruit-Images-Dataset/master/Test/Apple%20Braeburn/321_100.jpg\n",
        "                full_url = os.path.join(path_src, file_name)\n",
        "                !/usr/bin/wget $full_url\n",
        "                !/bin/mv $file_name $target_path\n",
        "        # Explore:  https://github.com/Horea94/Fruit-Images-Dataset/tree/master/Training/Apple%20Braeburn\n",
        "        download_source_file('yyy', ('100_100.jpg', '123_100.jpg', '307_100.jpg'), \n",
        "                            'https://github.com/Horea94/Fruit-Images-Dataset/raw/master/Training/Apple%20Braeburn/')\n",
        "        download_source_file('zzz', ('104_100.jpg', '122_100.jpg', '131_100.jpg', ), \n",
        "                            'https://github.com/Horea94/Fruit-Images-Dataset/raw/master/Training/Banana/')\n",
        "\n",
        "    while not weights_file_available:\n",
        "        print(f'    I: Waiting for weights download ... ')\n",
        "        time.sleep(2)\n",
        "\n",
        "    # Train models\n",
        "    print(f'Training model')\n",
        "    train_model(verbose=True)\n",
        "\n",
        "    filename = os.path.join(save_path, 'zzz/104_100.jpg')\n",
        "    # most_likely_class_label, max_pred = get_class_from_image(filename, class_names, verbose=True)\n",
        "    most_likely_class_label, max_pred = get_class_label_from_image(custom_model, filename, class_names, show_possibles=False)\n",
        "    print(f'{most_likely_class_label} ({max_pred*100:.3f}%)' )\n",
        "    \n",
        "    print(f'Finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cosfej3WhNvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tools\n",
        "def rem_dir(base_dir, class_name=None, verbose=False):\n",
        "    import shutil\n",
        "    base_dir_for_class = os.path.join(base_dir, class_name) if class_name else base_dir\n",
        "    if os.path.exists(base_dir_for_class):  \n",
        "        if(verbose): print(f'    Removing {base_dir_for_class}')\n",
        "        shutil.rmtree(base_dir_for_class)\n",
        "    else:\n",
        "        if(verbose): print(f'    Missing dir: {base_dir_for_class}')\n",
        "\n",
        "def get_only_classes_with_images(base_dir, class_names, min_num_images, verbose=False):\n",
        "    filtered_class_list = []\n",
        "    for class_name in class_names:\n",
        "        base_dir_for_class = os.path.join(base_dir, class_name) \n",
        "        if(verbose): log_msg(f'  Seaching: {base_dir_for_class}')\n",
        "        if not os.path.exists(base_dir_for_class): \n",
        "            if(verbose): print(f'    Missing dir: {base_dir_for_class}')\n",
        "            continue\n",
        "        file_list = [file_name for file_name in os.listdir(base_dir_for_class) if file_name.endswith('.jpg')]\n",
        "        if(verbose): log_msg(f'    Found: {file_list}')\n",
        "        # XXX Check file type\n",
        "        if(len(file_list) >= min_num_images):\n",
        "            filtered_class_list += (class_name, )\n",
        "    return filtered_class_list\n",
        "\n",
        "def get_class_list_from_widgets(v_box_classes, verbose=False):\n",
        "    # Get class list (non-whitespace names)\n",
        "    class_names = []\n",
        "    for h_box in v_box_classes.children:  # print(h_box)  \n",
        "        txt_class_name = h_box.children[0]\n",
        "        class_name = txt_class_name.value.strip()\n",
        "        if(len(class_name) > 0):\n",
        "            if(verbose): log_msg(f'  Adding class name [{class_name}]') \n",
        "            class_names.append(class_name)\n",
        "        else:\n",
        "            if(verbose): log_msg(f'  Empty class name - ignored') \n",
        "    return class_names\n",
        "\n",
        "def get_valid_class_list(base_dir, v_box_classes, verbose=False):\n",
        "    class_names = get_class_list_from_widgets(v_box_classes, verbose)\n",
        "    class_names = get_only_classes_with_images(base_dir, class_names, min_classes_to_train, verbose)\n",
        "    return class_names\n",
        "\n",
        "if False:\n",
        "    # XXX Need 3 dirs, at-least 2 with > imgaes present\n",
        "    base_dir = 'test_images'\n",
        "    class_names = ('AAA', 'BBB', 'kkk') ; print(f'  classes 0: {class_names}')\n",
        "    class_names = get_only_classes_with_images(base_dir, class_names, min_num_images=3, verbose=True)\n",
        "    print(f'  classes 1: {class_names}')\n",
        "\n",
        "    rem_dir(base_dir, class_name='kkk', verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijQgYcvxhtFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Handlers\n",
        "def handler_add_widgets_for_new_class(v_box_classes, row_num, num_images_to_acquire):\n",
        "\n",
        "    log_msg(f'Adding new object to train')\n",
        "\n",
        "    global model_initialised, model_trainable, model_trained\n",
        "    if not model_initialised:\n",
        "        log_msg(f'Initialising model ...')\n",
        "        # XXX\n",
        "        model_initialised = True\n",
        "\n",
        "    # Widgets\n",
        "    txt_class_name = widgets.Text(value='', placeholder='Type a name for the new object', description='Object Name:', disabled=False)\n",
        "    btn_acquire = widgets.Button(description='Take Photos', button_style='success', disabled = True, icon='camera')\n",
        "    box_images = widgets.HBox()\n",
        "    btn_remove = widgets.Button(description='Clear', button_style='danger', disabled = True, icon='remove')\n",
        "\n",
        "    def acquire_images_and_add(save_path, class_name, num_images_to_acquire, image_dims, box_images, verbose=False):\n",
        "        if(verbose): log_msg(f'* acquire_images_and_add({num_images_to_acquire} images to {save_path}, {class_name})')\n",
        "        img_filenames = capture_images_for_class(save_path, class_name, num_images_to_acquire, image_dims) #; print(filenames)\n",
        "        #img_filenames = ['test_images/AAA/image_000.jpg', 'test_images/AAA/image_001.jpg', 'test_images/AAA/image_002.jpg']\n",
        "        for filename in img_filenames:\n",
        "            html_image = get_image_as_html_tag(filename, width=50, height=50)\n",
        "            w = widgets.HTML(value = html_image,  placeholder='placeholder HTML' ) # XXX\n",
        "            box_images.children += (w,)\n",
        "        return img_filenames\n",
        "\n",
        "    # Wiring\n",
        "    def handler_name_change(obj):\n",
        "        # print(f'  Row: {row_num}, Handling name change [{txt_class_name.value}] class')\n",
        "        txt_class_name.value = txt_class_name.value.strip()    # XXX No spaces\n",
        "        if(len(txt_class_name.value) > 0):\n",
        "            btn_remove.disabled = False\n",
        "            btn_acquire.disabled = False\n",
        "        else:\n",
        "            btn_remove.disabled = True \n",
        "            btn_acquire.disabled = True\n",
        "    def handler_acquire_for_class(obj):\n",
        "        txt_class_name.disabled = True\n",
        "        btn_acquire.disabled = True\n",
        "        class_name = txt_class_name.value.strip()\n",
        "        # print(f'  Acquiring for {class_name} class,  Row: {row_num}, ')  # ;  print(f'  obj {obj}')\n",
        "        img_filenames = acquire_images_and_add(save_path, class_name, num_images_to_acquire, image_dims, box_images, verbose=True)\n",
        "        # Update other widgets\n",
        "        model_trained = False ; btn_identify.disabled = True\n",
        "        if(len(get_valid_class_list(save_path, v_box_classes)) >= min_classes_to_train): \n",
        "            model_trainable = True  ; btn_train.disabled = False \n",
        "            # print(f'  ** Enabled training ')  # ;  print(f'  obj {obj}')\n",
        "        #display_image_thumbnails(img_filenames)\n",
        "    def handler_clear_class(obj):\n",
        "        # Delete image files\n",
        "        class_name = txt_class_name.value.strip()\n",
        "        rem_dir(save_path, class_name, verbose=False)\n",
        "        # Clear widget\n",
        "        txt_class_name.value = ''\n",
        "        txt_class_name.disabled = False\n",
        "        box_images.children = []  # Do the discarded children need 'close()' called on each?\n",
        "        # Update other widgets\n",
        "        model_trained = False ; btn_identify.disabled = True\n",
        "        if(len(get_valid_class_list(save_path, v_box_classes)) < min_classes_to_train): \n",
        "            model_trainable = False ; btn_train.disabled = True\n",
        "            model_trained = False ; btn_identify.disabled = True\n",
        "\n",
        "    # Wiring\n",
        "    txt_class_name.observe(handler_name_change, names='value')\n",
        "    btn_acquire.on_click(handler_acquire_for_class)\n",
        "    btn_remove.on_click(handler_clear_class)\n",
        "\n",
        "    # Layout for row\n",
        "    h_box = widgets.HBox((txt_class_name, btn_acquire, box_images, btn_remove))\n",
        "    v_box_classes.children += (h_box,)    #; print(f'  Rows: {len(v_box_objects.children)}')\n",
        "\n",
        "def handler_learn_classes(v_box_classes):\n",
        "    log_msg(f'Getting classes from {len(v_box_classes.children)} rows')\n",
        "    # Get class list.  Ignore empty rows\n",
        "    class_names = get_valid_class_list(save_path, v_box_classes) \n",
        "    # Train\n",
        "    train_model(verbose=False)  # class_names) \n",
        "    model_trained = True; btn_identify.disabled = False\n",
        "\n",
        "def handler_identify(v_box_classes, widget_snapshot):\n",
        "    # Acquire image and identify\n",
        "    log_msg(f'Identifying')\n",
        "\n",
        "    # Get class names.  Ignore empty rows\n",
        "    class_names = get_valid_class_list(save_path, v_box_classes) \n",
        "\n",
        "    # Acquire image\n",
        "    image_dims = (image_width, image_height)\n",
        "    filename = 'photo.jpg'\n",
        "    filename, _, _ = acquire_webcam_image_to_file(filename, image_dims, await_button_click=False)  \n",
        "    widget_snapshot.value = '<h3>Snapshot to Identify</h3>' + get_image_as_html_tag(filename, width=100, height=100)\n",
        "\n",
        "    # Identify\n",
        "    global base_model, custom_model\n",
        "    most_likely_class_label, max_pred = get_class_label_from_image(custom_model, filename, class_names, show_possibles=True)\n",
        "    # XXX most_likely_class_label, max_pred = get_class_label_from_image(base_model, filename, class_names, show_possibles=True)\n",
        "\n",
        "    # Present results\n",
        "    # msg = f'Most likely:\\n\\n    {most_likely_class_label}     ({max_pred*100:.2f}%)\\n'\n",
        "    log_msg( f'Most likely:   {most_likely_class_label}     (approximately {max_pred*100:.2f}%)')\n",
        "    widget_snapshot.value += get_results_as_html_tag(most_likely_class_label, max_pred)\n",
        "    # XXX widget_snapshot.value += get_results_as_html_tag(most_likely_class_label, max_pred)\n",
        "\n",
        "def handler_stop_video(obj):\n",
        "    stop_live_webcam_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc7r-tfdiF-P",
        "colab_type": "code",
        "outputId": "cd7b44a2-df27-40f8-e469-cd669e8e171f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "# Widgets\n",
        "# Icons from https://www.w3schools.com/icons/icons_reference.asp  -> Font Awesome 4\n",
        "btn_add_class = widgets.Button(description='Add new object', button_style='success', disabled=False, icon='plus')\n",
        "btn_train = widgets.Button(description='Learn objects', button_style='success', disabled=True, icon='eye')  # star eye\n",
        "btn_identify = widgets.Button(description='Identify objects', button_style='success', disabled=True, icon='search-plus') # search-plus lightbulb\n",
        "btn_stop_video = widgets.Button(description='Stop Webcam', button_style='danger', disabled=False, icon='hand-stop-o')  # stop minus-circle hand-stop-o\n",
        "\n",
        "widget_video = widgets.HTML(get_html_live_video(width=500, height=300), layout=widgets.Layout(width='auto', grid_area='widget_video'))  # live webcam display + output log area (eg. )\n",
        "widget_snapshot = widgets.HTML(value = f\" \", layout=widgets.Layout(width='auto', grid_area='widget_snapshot')) \n",
        "#widget_results = widgets.HTML(value = f\"<b>placeholder</b> - results\", layout=widgets.Layout(width='auto', grid_area='widget_results'))\n",
        "\n",
        "widget_output = widgets.Output(layout={'height': '100px', 'width': '100%', 'border': '1px solid black', 'overflow':'scroll'})\n",
        "\n",
        "v_box_main = widgets.VBox()    #; print(v_box.children),  num_widget_rows = len(v_box_main.children)\n",
        "v_box_classes = widgets.VBox() \n",
        "#h_box_identify = widgets.HBox()\n",
        "\n",
        "# Wiring     \n",
        "btn_add_class.on_click(lambda obj : handler_add_widgets_for_new_class(v_box_classes, len(v_box_classes.children), num_images_to_acquire))\n",
        "btn_train.on_click(lambda obj : handler_learn_classes(v_box_classes))\n",
        "btn_identify.on_click(lambda obj : handler_identify(v_box_classes, widget_snapshot))\n",
        "btn_stop_video.on_click(handler_stop_video)\n",
        "\n",
        "# Layout\n",
        "# https://ipywidgets.readthedocs.io/en/latest/examples/Output%20Widget.html   and 'widget_output.clear_output()'\n",
        "#h_box_identify.children = (widget_video, widget_snapshot, widget_results)    #, widget_output) \n",
        "v_box_main.children = (btn_add_class, v_box_classes, btn_train, btn_identify)#, h_box_identify, btn_stop_video)\n",
        "#children = [btn_add_class, v_box_classes, btn_train, btn_identify, widget_video, widget_snapshot, btn_stop_video]\n",
        "children = [widget_video, widget_snapshot]\n",
        "areas = '''\n",
        "        \"widget_video widget_video . widget_snapshot\"\n",
        "        '''\n",
        "layout=widgets.Layout(width='800px',  # width='50%'\n",
        "            grid_template_rows='auto auto auto auto auto auto auto',\n",
        "            grid_template_columns='25% 25% 25% 25%',\n",
        "            grid_template_areas=areas)\n",
        "gridbox = widgets.GridBox(children=children, layout=layout)\n",
        "#display(HTML('<link rel=\"stylesheet\" href=\"//stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\"/>'))\n",
        "#display(v_box_main, gridbox, btn_stop_video) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-741f8a1e616a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbtn_add_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mButton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Add new object'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbutton_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'success'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0micon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'plus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbtn_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mButton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Learn objects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbutton_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'success'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0micon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eye'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# star eye\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbtn_identify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mButton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Identify objects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbutton_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'success'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0micon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'search-plus'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# search-plus lightbulb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbtn_stop_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mButton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Stop Webcam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbutton_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'danger'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0micon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hand-stop-o'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# stop minus-circle hand-stop-o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'widgets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6Pfu8MAi4aZ",
        "colab_type": "text"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-aQV7fq_RNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Widget enablement\n",
        "global model_initialised, model_trainable, model_trained\n",
        "model_initialised = False  ; model_trainable = False ; model_trained = False;\n",
        "\n",
        "# Clear the decks\n",
        "rem_dir(save_path)\n",
        "clear_output()\n",
        "\n",
        "# Display\n",
        "# Enable icons on widgets:  https://fontawesome.com/icons?d=gallery\n",
        "display(HTML('<link rel=\"stylesheet\" href=\"//stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\"/>'))\n",
        "display(v_box_main, gridbox, btn_stop_video) \n",
        "\n",
        "# Ensure logs visible in tab\n",
        "tab_bar = colab_widgets.TabBar(['Main', 'Logging'])\n",
        "with tab_bar.output_to(0, select=True):\n",
        "    print('Click on \"Logging\" tab to see logs')\n",
        "with tab_bar.output_to(1, select=False):\n",
        "    display(widget_output)\n",
        "\n",
        "# Load pre-trained CNN, in background\n",
        "log_msg(f'Loading pre-trained CNN, in background')\n",
        "init_load_weights_background(verbose=True)\n",
        "\n",
        "log_msg(f'Fin layout')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqc6K_ypimgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}